{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "import unstructured_client\n",
    "from unstructured_client.models import operations, shared\n",
    "\n",
    "client = unstructured_client.UnstructuredClient(\n",
    "    api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'unstructured_client' has no attribute 'partition'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43munstructured_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpartition\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'unstructured_client' has no attribute 'partition'"
     ]
    }
   ],
   "source": [
    "unstructured_client.partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import unstructured_client\n",
    "from unstructured_client.models import operations, shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def get_elements_from_file(filename):\n",
    "    with open(filename, \"rb\") as f:          # pass bytes, not a file handle\n",
    "        file_bytes = f.read()\n",
    "            # print first 10 bytes\n",
    "\n",
    "    req = operations.PartitionRequest(\n",
    "        partition_parameters=shared.PartitionParameters(\n",
    "            strategy=shared.Strategy.FAST,\n",
    "            files=shared.Files(\n",
    "                content=file_bytes,\n",
    "                file_name=filename,\n",
    "                \n",
    "            ),\n",
    "            \n",
    "            languages=[\"heb\", \"eng\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    client = unstructured_client.UnstructuredClient(\n",
    "        api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")\n",
    "    )\n",
    "\n",
    "    try:  \n",
    "        res = client.general.partition(request=req)\n",
    "        elements = res.elements                          # list of Element objects\n",
    "        \n",
    "        return elements\n",
    "    except SDKError as e:                                # friendlier error handling\n",
    "        print(f\"{e.status_code}: {e.message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2CuIov3dF0K9vnm1zu39yJa7QdYqNe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"UNSTRUCTURED_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matansharon/python/AI/unsructered/docs/Products/Bonded Manifolds/obsolete/Risk Management Plan - Bonded Manifolds.doc\n",
      "/Users/matansharon/python/AI/unsructered/docs/Products/Bonded Manifolds/obsolete/RMP - Bonded Manifolds.doc\n",
      "/Users/matansharon/python/AI/unsructered/docs/Products/Disposable PressureTransducer/obsolete/Risk Management Plan - Disposable Pressure Transducer.doc\n",
      "/Users/matansharon/python/AI/unsructered/docs/Products/Disposable PressureTransducer/obsolete/RMP- Disposable Pressure Transducer modifications.doc\n",
      "/Users/matansharon/python/AI/unsructered/docs/Products/Closed Stopcock & MRVLS/Obsolete/RMP - Closed Stopcock & MRVLS.doc\n",
      "/Users/matansharon/python/AI/unsructered/docs/Products/Closed Stopcock & MRVLS/Obsolete/Risk Management Plan - CSTP & MRVLS לא לשימוש.doc\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "def list_all_files(start: str | Path) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return a list of full (absolute) paths for every file\n",
    "    inside *start* and all its sub-directories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start : str | Path\n",
    "        The root folder to walk. Tilde (~) is expanded; the\n",
    "        path is resolved so the result is always absolute.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If *start* does not exist or is not a directory.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    \"\"\"\n",
    "    root = Path(start).expanduser().resolve()\n",
    "\n",
    "    if not root.is_dir():\n",
    "        raise FileNotFoundError(f\"{root} is not an existing directory\")\n",
    "\n",
    "    # rglob('*') walks recursively; p.is_file() filters out folders\n",
    "    return [str(p) for p in root.rglob('*') if p.is_file()]\n",
    "\n",
    "pathes=list_all_files(\"docs\")\n",
    "doc=[]\n",
    "for path in pathes:\n",
    "    filename=os.path.basename(path)\n",
    "    if filename.endswith(\".doc\"):\n",
    "        print(path)\n",
    "        doc.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "elements=[]\n",
    "for i in range(1,6):\n",
    "    el=get_elements_from_file(doc[i])\n",
    "    elements.append(el)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Header', 'element_id': 'df32bb9499063731ae7c2a472c41b75d', 'text': '3-01-21  SOP 4  Appendix Appendix status - released Revision  5 Valid from \\u200f25/12/2016 Product/s name Bonded Manifolds Document status Under Edit Author - Title Revision B Risk Management Plan Release Date - Document# Doc-075384 Page 8 of 8', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'header_footer_type': 'primary', 'languages': ['eng'], 'filetype': 'application/msword'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '11e96d58f19dcb0f91ee6f57e9131670', 'text': 'Company: Elcam Medical', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Company: Elcam Medical'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '5761d445000d8a3fbe516913c39b71e0', 'text': 'Product Description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Product Description:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '297a929bb065d15e8a587281927dcce7', 'text': 'The Bonded Manifolds family of products contains products that are alternative for Manifold-Monoblocks. They are 2,3 and 4 gang UV bonded manifold, LB and closed stopcocks.  ', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'daba200c1a05502b866d26a0844cf190', 'text': 'This Risk management plan covers all risk management activities required for bonded manifolds development projects as well as their design change projects.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '229734e5bad54f5cf5faf54905cb923e', 'text': 'Their lifecycle stages of such projects are divided to:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '10bc0b4a928a0830a349e22a76e982ff', 'text': 'project initiation', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '982570abb42bafdd6ba5faf06bc6128c', 'text': 'Design Planning', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '8d6188b8389217d6f7a46ee99ccc7cda', 'text': 'Design Input', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': 'f49c1e15ad8d7918065a64064ecfbea7', 'text': 'Design Output', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '012a16d145cbbba39bccb0ce32e24e8e', 'text': 'Design Verification & Validation', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': 'a5e9296b96ee0f7df156ac6370795088', 'text': 'Process Validation', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '186fd76d4ee66b25a7c46766410a2a35', 'text': 'Transfer to production', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '1f29cff370dbef0fb011c1c1ece2122d', 'text': 'Production & Post marketing.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': 'e9a456a5e4c36644d959ed9611d42eef', 'text': 'First Risk review meeting shall be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '1068137d4c77e0f5537ed56cec03a3d3', 'text': 'Purpose:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Purpose:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'b79ec06879a8a23d65d51c0ec5de0f4a', 'text': 'The purpose of this document is planning the risk management process for the Bonded Manifold family of products.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': 'c1e6c29233d471cf5850d4775fab103b', 'text': 'Definitions:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Definitions:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '29ff02ead2626b66fffbc21160822111', 'text': 'FMEA: Failure Mode and Effect Analysis.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '9403138b1ac975a3525430f226be1d87', 'text': 'Harm: physical injury or damage to the health of people, or damage to property or the environment.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '6516e21c2427c660c3180c76d51fa8c9', 'text': 'Hazard: potential source of harm. ', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '060f051affa02215353c15057918e996', 'text': 'Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ba441ac9711ab92d53cbbf9319c60f41', 'text': 'Risk: combination of the probability of occurrence of harm and the severity of that harm.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '4112adb8ab9360d46e8a8a9b471d7848', 'text': 'RPN: Risk Priority number', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'c5118d787edb6660c2275e0c701f6867', 'text': 'ALARP:  As Low As Reasonably Possible.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '05739e3077302102a8cb11a1ee3be597', 'text': 'AFAP:  As Far as Possible.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng', 'por'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': 'b7b109f60f39604f2cc3f6c1f3de2de9', 'text': 'Method:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Method:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '624fcdb841c6218e79e35a89c6a84f0e', 'text': '4.1. Risk Management Process description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.', 'Risk Management Process description:'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['fra', 'eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'daac3ce6df9388836a732d3d24237b8f', 'text': 'Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam\\'s SOP# 03-01-21.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'afefbbcefa6f439bf08f246d0dfc5cff', 'text': 'The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Risk Analysis', 'Risk Evaluation', 'Risk Control', 'Production & Post Production information.'], 'emphasized_text_tags': ['b', 'b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4ee608443a992f4c444ae64759533d30', 'text': '(The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['FMEA'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'af3313e506a01cb47957c1c2919c2e44', 'text': \"The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\", 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '29a4a91fc05adce4da84898edad244a5', 'text': '4.1.1. Risk Analysis:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.1.', 'Risk Analysis', 'Risk Analysis', ':'], 'emphasized_text_tags': ['b', 'b', 'i', 'i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7c8093b2dbb626741043ef0e0e463753', 'text': 'First step is listing the intended use or purpose of the product and its characteristics related to its safety. ', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '230da7636d3aabd3c6fd71906a09d87b', 'text': 'Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': [', identifying the known or foreseeable hazards and hazardous situations', 'causes', 'risks'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '96b7850e7b931d4e41bfc68db512dce9', 'text': '4.1.2. Risk Evaluation:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.2.', 'Risk Evaluation:', 'Risk Evaluation:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '5aa976aea791f7ee42bd7e1822257ded', 'text': 'The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['probability', '(P)', 'severity (S)', 'detectability (D)', 'RPN', 'acceptance criteria'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '91b21b8bc143a8ba62442007bbf5533a', 'text': 'Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['P', 'S', 'D'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ec26f0b1c4d52e5dc9060fa657bd2b50', 'text': 'Probability of occurrence (P):  ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Probability of occurrence', 'Probability of occurrence', '(', 'P', 'P'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'Table', 'element_id': 'a0bc5a6ea87bdfd7a52f44355af33d51', 'text': 'Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:100,000 - 1:1,000,000 Low probability, rare occurrence 4 1:100,000 - 1:10,000 Will occur several times 6 1:100 - 1:10,000 Will occur several times 8 More than 1:100 High probability, likely to occur frequently', 'metadata': {'emphasized_text_contents': ['Value', 'Probability for occurrence', 'Verbal description for probability'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'text_as_html': '<table><tr><td>Value</td><td>Probability for occurrence</td><td>Verbal description for probability</td></tr><tr><td>1</td><td>Less than 1 in 1,000,000</td><td>Evidence that will not occur</td></tr><tr><td>2</td><td>1:100,000 - 1:1,000,000</td><td>Low probability, rare occurrence</td></tr><tr><td>4</td><td>1:100,000 - 1:10,000</td><td>Will occur several times</td></tr><tr><td>6</td><td>1:100 - 1:10,000</td><td>Will occur several times</td></tr><tr><td>8</td><td>More than 1:100</td><td>High probability, likely to occur frequently</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '1b225602be95fd4fd28abe204372c4f9', 'text': 'Degree of Severity (S): ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Severity', 'Degree of Severity', '(', 'S', 'S'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'Table', 'element_id': '66750a4adab6a0823e7575cc6f96502f', 'text': 'S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.', 'metadata': {'emphasized_text_contents': ['S Rating', 'Severity', 'Severity to Patient/User', 'Severity to Elcam', 'Severity to Manufacture'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'text_as_html': '<table><tr><td>S Rating</td><td>Severity</td><td>Severity to Patient/User</td><td>Severity to Elcam</td><td>Severity to Manufacture</td></tr><tr><td>1</td><td>Minor</td><td>All is fine up to small discomfort, minor damage in performance.</td><td>All is fine up to deviations in spec border.</td><td>Small effect on equipment or product, a few production hours loss.</td></tr><tr><td>2</td><td>Medium</td><td>Degradation in performance without harm.</td><td>Damage to image, do not meet spec.</td><td>Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss.</td></tr><tr><td>4</td><td>Severe</td><td>The part does not function but does not cause harm.</td><td>Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec.</td><td>Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss.</td></tr><tr><td>6</td><td>Severe - critical</td><td>The product does not function and causes injury or condition requiring medical treatment.</td><td>Severe impact to image, product will not meet the requirements of spec, market loss.</td><td>High deterioration in equipment or its operation severely affecting production or product functionality, several week losses.</td></tr><tr><td>8</td><td>Critical</td><td>Severe harm to patient: death, irreversible injury or condition or long term medical aid.</td><td>Low suit, market loss.</td><td>Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'ListItem', 'element_id': '3724cbe1ee9f317db79d6089c38256ed', 'text': 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'b60755a820877c47e1234a7cc80c608e', 'text': 'Degree of Detectability (D): ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Detectability (D):', 'Degree of Detectability (D):'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'Table', 'element_id': '6dab75f84074a9700636f8f21736af38', 'text': 'D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.', 'metadata': {'emphasized_text_contents': ['D Rating', 'Defect Detection'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'text_as_html': '<table><tr><td>D Rating</td><td>Defect Detection</td></tr><tr><td>1</td><td>Defect, if occurred, will always be detected at Elcam during production.</td></tr><tr><td>2</td><td>Defect, if occurred, will occasionally be detected at Elcam during production.</td></tr><tr><td>3</td><td>Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user).</td></tr><tr><td>4</td><td>Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'Title', 'element_id': '43439fd61b01fcaeff82dc4223b2eff7', 'text': 'RPN calculation:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['RPN calculation:'], 'emphasized_text_tags': ['i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'df32bb9499063731ae7c2a472c41b75d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6728d80b6d87841078ba65dfe2112933', 'text': 'The calculation of the Risk Priority Number (RPN) is done by multiplying the risk analysis values:            (S x P) or (S x P x D).', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['(S x P)', '(S x P x D)'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '3b884d84b99886e6753d11e6198c4dc6', 'text': 'According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). ', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '6eb9612ae1b91d7c9d9ec6678d965ecf', 'text': 'Risk Priority Levels:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'Table', 'element_id': '33c0075b858fda907121ccb2eabf1015', 'text': '(S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P)<32 (Yellow) Medium (ALARP/AFAP*) 32≤(S*P) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P) value', 'Color', 'Risk priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'text_as_html': '<table><tr><td>(S*P) value</td><td>Color</td><td>Risk priority Level</td></tr><tr><td>(S*P)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P)&lt;32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32≤(S*P)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '177abc6c8bf845aae17147cc3edf5ac7', 'text': 'Or', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'Table', 'element_id': '13f7d51efcaea9ba158a14340735ea0b', 'text': '(S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P*D) value', 'Color', 'Risk Priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'text_as_html': '<table><tr><td>(S*P*D) value</td><td>Color</td><td>Risk Priority Level</td></tr><tr><td>(S*P*D)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P*D)≤32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32&lt;(S*P*D)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6042c7af03ae60e355dacdfeb7eb6ac0', 'text': 'Green area – Low rated risks.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Green area –'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '32e82547d3848aedc15c96631568039e', 'text': 'Yellow area – Medium rated risks. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Yellow area'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': 'b22d231df18ba8f874aabaa774ad9cc6', 'text': 'Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['*'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '58b2bf0215db26f6744e1206af8611c9', 'text': 'Red area – High rated risk, additional actions should be taken to reduce this risk. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Red area'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '016b4a97fa2f1934d5515e01ff1f1828', 'text': '4.1.3. Risk Control:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.3.', 'Risk Control:', 'Risk Control:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '201ed61ec9a69ab2bbb61232ed563495', 'text': 'For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9c66ed95c9a90146c6be62ae83b214eb', 'text': 'The risk control measures should be one or more of the following options in the priority order listed:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': '9d7f0eb43acaccc304bbb0abc760aa80', 'text': 'Inherent safety by design', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': 'd77376612515eaaa39eb9484fde3ea0c', 'text': 'Protective measures in the product itself or in the manufacturing process.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': '9ee8e53845b3fbba35883c6f5b3f5f15', 'text': 'Information for safety', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '27b378a922d9a2e231d18ae0ec4a4ed0', 'text': 'Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['defining', 'Implementation', 'Residual Risk Evaluation', 'Risk to Benefit Analysis', 'Risks arising from the risk control measures'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'b99d1dd7d13514d6145efa67b6fd2e24', 'text': 'At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Acceptability of the Overall Residual Risk'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '260c7c8ccd02086500a4a568888d5855', 'text': '4.1.4. Production & Post-production Information:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.4.', 'Production & Post-production Information:', 'Production & Post-production Information:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6697c3124c2d43aed125ad286e6608f6', 'text': \"After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\", 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '7a538e513085a40ff6a906979e90a8fc', 'text': '4.2. Verification plan', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.2. Verification plan'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': 'c80b9f69dcd3a5fdb2b5001c5d861488', 'text': 'After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': '938618f9de7adfdf5fdeb31fb650ecc1', 'text': 'The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': '0a87eadac65bd9af509cb27b12a33455', 'text': 'Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': '16368b81aff78dd37e97d779e1c6f013', 'text': 'Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': '581c95123b938912bd9ce6b4ed32aaed', 'text': 'Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'b81937e919b658b7a940899ceb5dbfd4', 'text': '4.3. Allocation of responsibilities:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3. Allocation of responsibilities:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'af9015b6f646024d252fb0ca841ac702', 'text': '4.3.1. Responsibility for assuring that the risk management activities are done is by the Project Manager.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.1.'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '7b631988260332474b88b679f71e2d86', 'text': '4.3.2. Person In charge for Risk Management activities execution: Quality Engineer in R&D.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.2.'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e1c93fbf54831f2d131f58568b0f36fc', 'text': '4.3.3. Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.3.'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'd45c2a7b131c29fca007c2f70d52e05b', 'text': '4.3.4. Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.4'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '864b9af062b67cc57f3e1caef9597e68', 'text': '4.3.5. Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.5'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': '35888ecbc25fbf631310e240c7839ba8', 'text': 'Documenting Risk Management Process', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Documenting Risk Management Process'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '8e6fba021fd3eeaad6a1f210033e97ab', 'text': \"The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\", 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6fa69259ce9f5183ad5b2722ddd73c1b', 'text': 'Risk general management documents related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': 'feda67cc649fede5532adfd3cb6fee0b', 'text': 'Summary', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Summary'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'NarrativeText', 'element_id': '989768d90022d2810bbef3db73de373f', 'text': 'This document outlines the risk management activities for Bonded Manifold family of products. It determines the scales of rating them and the acceptance criteria. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': 'faf2715a35fadcf65ee2a7d5c8c57c1e', 'text': 'Document Revision Control:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'Table', 'element_id': '2d362c0d361beff2c3e32cf03213ffa8', 'text': 'Revision History Tracking: Date: Revision 0- first version 5-July-2012 Revision A – update of referenced standards and definition of ALARP/AFAP in addition to Change of format and also having this document general for all customers. 16-Mar-2014 Revision B – Updating document format; Adding to section 1 timing along product lifecycle for risk management activities; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 \"Responsibilities\" and 4.3. \"Allocation of responsibilities\". 27-Dec-2016', 'metadata': {'emphasized_text_contents': ['Revision History Tracking:', 'Revision B –'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP - Bonded Manifolds.doc', 'text_as_html': '<table><tr><td>Revision History Tracking:</td><td>Date:</td></tr><tr><td>Revision 0- first version</td><td>5-July-2012</td></tr><tr><td>Revision A – update of referenced standards and definition of ALARP/AFAP in addition to Change of format and also having this document general for all customers.</td><td>16-Mar-2014</td></tr><tr><td>Revision B – Updating document format; Adding to section 1 timing along product lifecycle for risk management activities; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 &quot;Responsibilities&quot; and 4.3. &quot;Allocation of responsibilities&quot;.</td><td>27-Dec-2016</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'ListItem', 'element_id': '8502f8b6312e73dc868e99731b5331a1', 'text': 'Review and approval:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Bonded Manifolds.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'Table', 'element_id': 'f23244757d084c5d4ce8f54f20c1c87c', 'text': 'Written by: Name Date Signature QA Eng. - - -', 'metadata': {'emphasized_text_contents': ['Written by:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'text_as_html': '<table><tr><td>Written by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>QA Eng.</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng', 'deu'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'Table', 'element_id': '8320478da37d61f01991f58030620e00', 'text': 'Reviewed & Approved by: Name Date Signature R&D Director /VP - - - VP of QA & RA/ QA Manager R&D - - -', 'metadata': {'emphasized_text_contents': ['Reviewed & Approved by:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Bonded Manifolds.doc', 'text_as_html': '<table><tr><td>Reviewed &amp; Approved by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>R&amp;D Director /VP</td><td>-</td><td>-</td><td>-</td></tr><tr><td>VP of QA &amp; RA/ QA Manager R&amp;D</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '43439fd61b01fcaeff82dc4223b2eff7'}}\n",
      "{'type': 'Header', 'element_id': 'da6ddb1840eca638f6dc476c360e9c2e', 'text': 'SOP 3-01-21 4  Appendix Appendix status - released Revision  7 Valid from \\u200f20/04/2017 Product/s name Disposable Pressure Transducer Document status Under Edit Author - Title Revision C Risk Management Plan Release Date - Document# Doc-081938 Page 7 of 7', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'header_footer_type': 'primary', 'languages': ['eng'], 'filetype': 'application/msword'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '1a3609b18c75c9f19be6ace34811162f', 'text': 'Company: Elcam Medical', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Company: Elcam Medical'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': '2618d3c55b2161b90a7d858dfa24bcae', 'text': 'Product Description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Product Description:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7b3e24ae126c2a93fec1a240c8ef34f9', 'text': 'The DPT (Disposable Pressure Transducer) is a product used for arterial blood pressure sensing. There are two versions DIPT (Integrated DPT) and DPT (also called DSPT -Straight DPT).', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '19e061e49cb94168f4422a2351665a6d', 'text': 'This Risk management plan covers all risk management activities required for the design change projects of the high pressure stopcocks.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '19425aa6de42e648546f0d2512f79cd3', 'text': 'Projects lifecycles are usually divided to:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Projects lifecycles are usually divided to:'], 'emphasized_text_tags': ['i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': '0a2e699bbe98ff97d8ba01fc23e86bc4', 'text': 'project initiation', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': '9ccd5676b84a58e3973ccc844f82b2da', 'text': 'Design Planning', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'aa75a138af7fb697fdd25c9d074bd946', 'text': 'Design Input', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'b6d1b39f5eb213b1e3736728cd3d4fec', 'text': 'Design Output', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': '786042a40127f4471f8cb79dcf7481b4', 'text': 'Design Verification & Validation (V&V)', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['ita', 'eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'b8d9db3776787c5a189ad1192adc472e', 'text': 'Process Validation', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'fa91cd9007ab113ebe89807b43a765e4', 'text': 'Transfer to production', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'e87d33e11ae82800f1ac1d3393542ac9', 'text': 'Production and post marketing', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': '2f65540b0988e9b8a05feef4adc63911', 'text': 'First Risk review meeting is to be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'c97574975bea4fa67c3b53013b345f18', 'text': 'Purpose:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Purpose:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'f63692a4eb21e6621bd9c4110fdbc47a', 'text': 'The purpose of this document is planning the risk management process for the Disposable Pressure Transducer family of products.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'fd320d2964fc4be3df4753f62e4a59dc', 'text': 'Definitions:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Definitions:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '77364d180438def3611ae4b314940aba', 'text': 'FMEA: Failure Mode and Effect Analysis.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'b9c1da740e69f1861013fb7c2b7f1524', 'text': 'Harm: physical injury or damage to the health of people, or damage to property or the environment.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'f3dba868c44de50ab580f0617572b19b', 'text': 'Hazard: potential source of harm. ', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'ada1caefbbbb3fb5b1f06a0a6bfd74c2', 'text': 'Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '99b8cb8f545b236a30c2720ff326761e', 'text': 'Risk: combination of the probability of occurrence of harm and the severity of that harm.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '7f2d115fe3409e7b7c87b3f34a3c4597', 'text': 'RPN: Risk Priority number, Multiply of Severity*Probability*Detectability.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '231306169d0f96e1ce7f64ebe1521532', 'text': 'ALARP:  As Low As Reasonably Possible.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '63e5ac197c85ef11e4c147a3851eb1ea', 'text': 'AFAP:  As Far as Possible.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng', 'por'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'd519f15847e871db3e2d7e6eb40b5d55', 'text': 'Method:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Method:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'b83f6ca087cdb1fdea6072dfb930c47b', 'text': '4.1. Risk Management Process description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.', 'Risk Management Process description:'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['fra', 'eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'bf4d7084a16b350b2d4ca930c20520c4', 'text': 'Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam\\'s SOP# 03-01-21.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '88b4785352096a4b250ebcead18e8599', 'text': 'The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Risk Analysis', 'Risk Evaluation', 'Risk Control', 'Production & Post Production information.'], 'emphasized_text_tags': ['b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'abadba19bb51dadce7177da074fcb95d', 'text': '(The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['FMEA'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '682c0db024e48e87a700043de3020dcd', 'text': \"The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\", 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '49b39a6dbb1f134d4712411414c26e9b', 'text': '4.1.1. Risk Analysis:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.1.', 'Risk Analysis', 'Risk Analysis', ':'], 'emphasized_text_tags': ['b', 'b', 'i', 'i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e4c38a528641d948dce43e2170253f9a', 'text': 'First step is listing the intended use or purpose of the product and its characteristics related to its safety. ', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7142bd3d4cb774474c6cd05ea86ac520', 'text': 'Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': [', identifying the known or foreseeable hazards and hazardous situations', 'causes', 'risks'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '67e0828793335f68bf18640d92e7492c', 'text': '4.1.2. Risk Evaluation:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.2.', 'Risk Evaluation:', 'Risk Evaluation:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6a8b92beefc29b2fcec759c8dc99a0f4', 'text': 'The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['probability', '(P)', 'severity (S)', 'detectability (D)', 'RPN', 'acceptance criteria'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '894ee1f8929c3621bf42e2c4771a9aca', 'text': 'Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['P', 'S', 'D'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '5fdd226026f41433d66a0989d201ef90', 'text': 'Probability of occurrence (P):  ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Probability of occurrence', 'Probability of occurrence', '(', 'P', 'P'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'Table', 'element_id': '091e8b4ac912294bee408e72b0ee7824', 'text': 'Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:10,000 - 1:1,000,000 Low probability, rare occurrence 4 1:1,000 - 1:10,000 Will occur several times 6 1:100 - 1:1,000 Will occur several times, often 8 More than 1:100 High probability, likely to occur frequently', 'metadata': {'emphasized_text_contents': ['Value', 'Probability for occurrence', 'Verbal description for probability'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'text_as_html': '<table><tr><td>Value</td><td>Probability for occurrence</td><td>Verbal description for probability</td></tr><tr><td>1</td><td>Less than 1 in 1,000,000</td><td>Evidence that will not occur</td></tr><tr><td>2</td><td>1:10,000 - 1:1,000,000</td><td>Low probability, rare occurrence</td></tr><tr><td>4</td><td>1:1,000 - 1:10,000</td><td>Will occur several times</td></tr><tr><td>6</td><td>1:100 - 1:1,000</td><td>Will occur several times, often</td></tr><tr><td>8</td><td>More than 1:100</td><td>High probability, likely to occur frequently</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '81d4dcad0c0de6e3037430c8ec13d3f3', 'text': 'Degree of Severity (S): ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Severity', 'Degree of Severity', '(', 'S', 'S'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'Table', 'element_id': '191aa38eeb116ec0883f3a3ad45b44c8', 'text': 'S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.', 'metadata': {'emphasized_text_contents': ['S Rating', 'Severity', 'Severity to Patient/User', 'Severity to Elcam', 'Severity to Manufacture'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'text_as_html': '<table><tr><td>S Rating</td><td>Severity</td><td>Severity to Patient/User</td><td>Severity to Elcam</td><td>Severity to Manufacture</td></tr><tr><td>1</td><td>Minor</td><td>All is fine up to small discomfort, minor damage in performance.</td><td>All is fine up to deviations in spec border.</td><td>Small effect on equipment or product, a few production hours loss.</td></tr><tr><td>2</td><td>Medium</td><td>Degradation in performance without harm.</td><td>Damage to image, do not meet spec.</td><td>Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss.</td></tr><tr><td>4</td><td>Severe</td><td>The part does not function but does not cause harm.</td><td>Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec.</td><td>Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss.</td></tr><tr><td>6</td><td>Severe - critical</td><td>The product does not function and causes injury or condition requiring medical treatment.</td><td>Severe impact to image, product will not meet the requirements of spec, market loss.</td><td>High deterioration in equipment or its operation severely affecting production or product functionality, several week losses.</td></tr><tr><td>8</td><td>Critical</td><td>Severe harm to patient: death, irreversible injury or condition or long term medical aid.</td><td>Low suit, market loss.</td><td>Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'ListItem', 'element_id': 'ece0bdbb8d59b871646c6543d9662faf', 'text': 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '6f6ef86fc03a2128037e4735e9a28ee9', 'text': 'Degree of Detectability (D) – Relevant mainly to Process risks: ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Detectability (D) – Relevant mainly to Process risks:', 'Degree of Detectability (D) – Relevant mainly to Process risks:'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'Table', 'element_id': '41e35a54ab5427eafa3f51cf4513c98c', 'text': 'D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.', 'metadata': {'emphasized_text_contents': ['D Rating', 'Defect Detection'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'text_as_html': '<table><tr><td>D Rating</td><td>Defect Detection</td></tr><tr><td>1</td><td>Defect, if occurred, will always be detected at Elcam during production.</td></tr><tr><td>2</td><td>Defect, if occurred, will occasionally be detected at Elcam during production.</td></tr><tr><td>3</td><td>Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user).</td></tr><tr><td>4</td><td>Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'Title', 'element_id': '30e495e6db5bbeb7d9f63818e3584152', 'text': 'RPN calculation:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['RPN calculation:'], 'emphasized_text_tags': ['i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'da6ddb1840eca638f6dc476c360e9c2e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'bfa6af8290e8e614dd6988a59bf4869b', 'text': 'The calculation of the Risk Priority Number (RPN) is done by multiplying the risk values:         (S x P) or (S x P x D).', 'metadata': {'category_depth': 0, 'emphasized_text_contents': [':', '(S x P)', '(S x P x D)'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e629140033ba01c3f103b7654e0ec825', 'text': 'According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). ', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ae9fb3486ff1174443db6635a854ec97', 'text': 'Risk Priority Levels:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'Table', 'element_id': '4d65604d1f0dd8ed936d9299891c8a85', 'text': '(S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P) ≤32 (Yellow) Medium (ALARP/AFAP*) 32< (S*P) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P) value', 'Color', 'Risk priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'text_as_html': '<table><tr><td>(S*P) value</td><td>Color</td><td>Risk priority Level</td></tr><tr><td>(S*P)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P) ≤32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32&lt; (S*P)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '6ec4605bcc5f1dcff4a357a6b01a6028', 'text': 'Or', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'Table', 'element_id': '4f34b2ac620efd2f15567db0fbc6b4f1', 'text': '(S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P*D) value', 'Color', 'Risk Priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'text_as_html': '<table><tr><td>(S*P*D) value</td><td>Color</td><td>Risk Priority Level</td></tr><tr><td>(S*P*D)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P*D)≤32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32&lt;(S*P*D)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7962aee9ef835c285b8c1004e639093f', 'text': 'Green area – Low rated risks.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Green area –'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '61df2a2869e67d5db4990bd834001008', 'text': 'Yellow area – Medium rated risks. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Yellow area'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': 'ddd712cffba49ec901aa4784ffd4e550', 'text': 'Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'bf2da98ef6cb0b61c90626fd9d9cdb06', 'text': 'Red area – High rated risk, additional actions should be taken to reduce this risk. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Red area'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ff4670428a70faaefa72fa414eb9d2ee', 'text': '4.1.3. Risk Control:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.3.', 'Risk Control:', 'Risk Control:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '35230bae6f42cc6e44af0a8001f83142', 'text': 'For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '59be935892afe80603976024273d25f9', 'text': 'The risk control measures should be one or more of the following options in the priority order listed:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': '4444979c1b609473a766933264a7a157', 'text': 'Inherent safety by design', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': '3887ae572c667a34a23661ec2e0a8b03', 'text': 'Protective measures in the product itself or in the manufacturing process.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': 'ace4af06440a2cd2670e6f0b16ba2d1b', 'text': 'Information for safety', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6de42496e91cbaf46cdfe7857eeaa3a8', 'text': 'Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['defining', 'Implementation', 'Residual Risk Evaluation', 'Risk to Benefit Analysis', 'Risks arising from the risk control measures'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '752756e306d31c1be4aa0c27b2821a0b', 'text': 'At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Acceptability of the Overall Residual Risk'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '86c645e7ac01ded9401460dd0defcdb7', 'text': '4.1.4. Production & Post-production Information:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.4.', 'Production & Post-production Information:', 'Production & Post-production Information:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '99aef7a535ce54ea906b544eaa2300f5', 'text': \"After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\", 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '5d072a9f37912959d85f317e3854851f', 'text': '4.2. Verification plan', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.2. Verification plan'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': 'c3d63fbb1e07299846787ddfca7b745b', 'text': 'After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': '93b62489472dddeb428a70e8ae7c9b57', 'text': 'The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': 'fa5e4d2a97ee91c2be4ff572042723ed', 'text': 'Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': '9f7a7cfae90620d29a51b8d02085a083', 'text': 'Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': 'fe3ff006adc8012752299926c764a462', 'text': 'Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '41ff52beb34375b727814e48c77c22fc', 'text': '4.3. Allocation of responsibilities:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3. Allocation of responsibilities:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '69eb5f1f17c253750857163855e7e904', 'text': '4.3.1. Responsibility for assuring that the risk management activities are done is by the Project Manager.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.1.'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '905ef9c994e2bc90d97edd13064fd391', 'text': '4.3.2. Person In charge for Risk Management activities execution: Quality Engineer in R&D.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.2.'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6a90dc62e60cf0dd204ffa872ac8712c', 'text': '4.3.3. Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.3.'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'f072c4391b17b14b3ec30421752cf7c4', 'text': '4.3.4. Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.4'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'df3528683285d8aedf8ea107a9f42dc4', 'text': '4.3.5. Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.5'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': '0c52733dcf2074a4ed3cb26e625dbe9c', 'text': 'Documenting Risk Management Process', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Documenting Risk Management Process'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '5fa0e22b51a4a368064487a3676b2f21', 'text': \"The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 or 8 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\", 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'NarrativeText', 'element_id': '56eedb63f570854442fc1a50ee2e9e2e', 'text': 'General Risk management documents (for family of products) related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system and using appendix 7 of SOP 3-01-21. ', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': 'd78518a0c599f35b3b6be26922266f89', 'text': 'Summary', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Summary'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': '83349fd162d5e23c7dd46b786c16c220', 'text': 'This document outlines the risk management activities for the Disposable Pressure Transducer family of products. It determines the scales of rating them and the Risk Priority Levels. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': '271f77bc1059562b210b28330d0919bd', 'text': 'Document Revision Control:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'Table', 'element_id': '9c5269059f5211f34fc856477c7cc1a0', 'text': 'Revision History Tracking: Date: Revision 0- first release 19-Nov-2008 Revision A - Overall review and updates 30-Dec-2014 Revision B - Updating document format. Adding definitions of ALARP and AFAP to section 3. Updating Risk evaluation definitions in section 4.1.2.according to the new version of annexes 5, 7 and 8 of SOP 3-01-21. Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks) and Updating location of general risk documents (in the EPDM system). 12-Jan-2017 Revision C - Correcting Probability scales and Risk Priority Levels according latest version of Appendix 5, 7 and 8 of SOP 3-01-21. Adding guidance for using appendix 5, 7 and 8 of SOP 3-01-21 to \"Documenting Risk Management Process\" section. 16-Aug-2017', 'metadata': {'emphasized_text_contents': ['Revision History Tracking:', '-'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'text_as_html': '<table><tr><td>Revision History Tracking:</td><td>Date:</td></tr><tr><td>Revision 0- first release</td><td>19-Nov-2008</td></tr><tr><td>Revision A - Overall review and updates</td><td>30-Dec-2014</td></tr><tr><td>Revision B - Updating document format. Adding definitions of ALARP and AFAP to section 3. Updating Risk evaluation definitions in section 4.1.2.according to the new version of annexes 5, 7 and 8 of SOP 3-01-21. Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks) and Updating location of general risk documents (in the EPDM system).</td><td>12-Jan-2017</td></tr><tr><td>Revision C - Correcting Probability scales and Risk Priority Levels according latest version of Appendix 5, 7 and 8 of SOP 3-01-21. Adding guidance for using appendix 5, 7 and 8 of SOP 3-01-21 to &quot;Documenting Risk Management Process&quot; section.</td><td>16-Aug-2017</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'ListItem', 'element_id': 'b5655d9a8f58cd133270485a9dbfaf35', 'text': 'Review and approval:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'Table', 'element_id': '8a2f6efed247f9d6f336ba6eafe052e2', 'text': 'Written by: Name Date Signature QA Eng. - - -', 'metadata': {'emphasized_text_contents': ['Written by:', 'Name', 'Date', 'Signature'], 'emphasized_text_tags': ['b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'text_as_html': '<table><tr><td>Written by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>QA Eng.</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng', 'deu'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'Table', 'element_id': 'f9cee917d3075fa1a1e8915154e1c5f6', 'text': 'Reviewed & Approved by: Name Date Signature Chief Technology Officer /R&D Manager - - - Chief Quality & RA Officer/ QA Manager R&D - - -', 'metadata': {'emphasized_text_contents': ['Reviewed & Approved by:', 'Name', 'Date', 'Signature'], 'emphasized_text_tags': ['b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - Disposable Pressure Transducer.doc', 'text_as_html': '<table><tr><td>Reviewed &amp; Approved by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>Chief Technology Officer /R&amp;D Manager</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Chief Quality &amp; RA Officer/ QA Manager R&amp;D</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '30e495e6db5bbeb7d9f63818e3584152'}}\n",
      "{'type': 'Header', 'element_id': '158f7513186e2f0d8d91159d90271fc3', 'text': '3-01-21  SOP 4  Appendix Appendix status - released Revision  5 Valid from \\u200f25/12/2016 Product/s name - Document status Under Edit Author - Title Revision B Risk Management Plan Release Date - Document# Doc-076035 Page 7 of 7', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'header_footer_type': 'primary', 'languages': ['eng'], 'filetype': 'application/msword'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '9b9eab6405af07d95c21e6e2f9a1ca87', 'text': 'Company: Elcam Medical', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Company: Elcam Medical'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '14009ae4ad46a35a92b78e4105c78f03', 'text': 'Product Description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Product Description:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '00ee2aa4c2625dcae529297d99c4e7e9', 'text': 'The DPT (Disposable Pressure Transducer) is a product used for arterial blood pressure sensing. There are two versions DIPT (Integrated DPT) and DPT (also called DSPT -Straight DPT).', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '65ce5181cda4164635b152b9d89e74b7', 'text': 'This Risk management plan covers all risk management activities required for the design change projects of the high pressure stopcocks.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '1f0ab9ba368f4a86685d692ca6a862c1', 'text': 'Projects lifecycles are usually divided to:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Projects lifecycles are usually divided to:'], 'emphasized_text_tags': ['i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '87c965accea762a7c77f5f7a1c36e517', 'text': 'project initiation', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': 'b9e281dd782cc84466605b2cb8535efe', 'text': 'Design Planning', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '3f2bebf6fa4b6ba03371298def37c67b', 'text': 'Design Input', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': 'a55d737c14f66f904be39bcc0ddf6b76', 'text': 'Design Output', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '0b20f28f075e7d2cfcfd150d00f20000', 'text': 'Design Verification & Validation (V&V)', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['ita', 'eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': 'ec969079a8da140201a237e67bd4dc3d', 'text': 'Process Validation', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': 'c1d60f38ffd68b3c53d428c6e23c3d1c', 'text': 'Transfer to production', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': 'dabadf926b0fd6b0a48c4dcf0340f632', 'text': 'Production and post marketing', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '4b2783b7ac0068029caa9472c53cf6d6', 'text': 'First Risk review meeting is to be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': 'fd5e5b1374c3505c4e8bdfa04a401e9c', 'text': 'Purpose:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Purpose:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7a2e1e489faa7f7befbbbff8895f2ec7', 'text': 'The purpose of this document is planning the risk management process for the Disposable Pressure Transducer modifications.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '31f2cc0dd476c8528cc4e772005d1783', 'text': 'Definitions:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Definitions:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '5d582751924646f4965b80a032d9aa6c', 'text': 'FMEA: Failure Mode and Effect Analysis.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ac467e5ba4217512caa7f891afc562da', 'text': 'Harm: physical injury or damage to the health of people, or damage to property or the environment.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '74f1aeeab835d85ff89b8816b9a79eac', 'text': 'Hazard: potential source of harm. ', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '03be2ff645b48badb9e0ce84a68a59af', 'text': 'Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '111a3e1852f1d878913fd337b344a174', 'text': 'Risk: combination of the probability of occurrence of harm and the severity of that harm.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '3924deff92c456ba1c9efd55eec2c0b5', 'text': 'RPN: Risk Priority number, Multiply of Severity*Probability*Detectability.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '0e0bf16638b35b5d265fc1cc9c7b4044', 'text': 'ALARP:  As Low As Reasonably Possible.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'c1b20c8207bdac1a3491605f3072eb54', 'text': 'AFAP:  As Far as Possible.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng', 'por'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '182eefe8c74373745bb39ac18be93b7f', 'text': 'Method:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Method:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '7051283759c7acdecb526741e54b5e01', 'text': 'Risk Management Process description:', 'metadata': {'category_depth': 1, 'emphasized_text_contents': ['Risk Management Process description:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '182eefe8c74373745bb39ac18be93b7f'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4cc478afc092b98d1e6bb4e47a0c328c', 'text': 'Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam\\'s SOP# 03-01-21.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'e86925e8d1cc72749a80c0260596cd5b', 'text': 'Method description ', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '2f0fac066f7c0a3141f736c45d743470', 'text': 'The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e317fa41b55a0df9ebb9877838afd83a', 'text': 'The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. ', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '95ee15ea0bdba886403c82e401fb3afe', 'text': \"The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\", 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '713d058b7c1a35d47129267559846ef1', 'text': 'Risk Analysis:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['Risk Analysis', 'Risk Analysis', ':'], 'emphasized_text_tags': ['b', 'i', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e4755985611b2e0bd67d489fb1a590d5', 'text': 'First step is listing the intended use or purpose of the product and its characteristics related to its safety. ', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '3d94fa4770bf65e80ae3558de79f02e6', 'text': 'Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': [', identifying the known or foreseeable hazards and hazardous situations', 'causes', 'risks'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '193e097b5a4b5cc8a56950e3d7cd3ca7', 'text': 'Risk Evaluation:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['Risk Evaluation:', 'Risk Evaluation:'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'd57d0dfe254738df0295099da0afb37a', 'text': 'The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['probability', '(P)', 'severity (S)', 'detectability (D)', 'RPN', 'acceptance criteria'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7cc540c4b5500ebd081ae639a81a5302', 'text': 'Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['P', 'S', 'D'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'edd3243210cd138020cf4bda6192956d', 'text': 'Probability of occurrence (P):  ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Probability of occurrence', 'Probability of occurrence', '(', 'P', 'P'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'Table', 'element_id': '1f3927bed22295c43109ac2271f0b3c2', 'text': 'Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:100,000 - 1:1,000,000 Low probability, rare occurrence 4 1:100,000 - 1:10,000 Will occur several times 6 1:100 - 1:10,000 Will occur several times 8 More than 1:100 High probability, likely to occur frequently', 'metadata': {'emphasized_text_contents': ['Value', 'Probability for occurrence', 'Verbal description for probability'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'text_as_html': '<table><tr><td>Value</td><td>Probability for occurrence</td><td>Verbal description for probability</td></tr><tr><td>1</td><td>Less than 1 in 1,000,000</td><td>Evidence that will not occur</td></tr><tr><td>2</td><td>1:100,000 - 1:1,000,000</td><td>Low probability, rare occurrence</td></tr><tr><td>4</td><td>1:100,000 - 1:10,000</td><td>Will occur several times</td></tr><tr><td>6</td><td>1:100 - 1:10,000</td><td>Will occur several times</td></tr><tr><td>8</td><td>More than 1:100</td><td>High probability, likely to occur frequently</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '46048b0055dcc5e5b1267b74f985370b', 'text': 'Degree of Severity (S): ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Severity', 'Degree of Severity', '(', 'S', 'S'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'Table', 'element_id': 'b5587a451ef31f4f38f0015d25d2e188', 'text': 'S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.', 'metadata': {'emphasized_text_contents': ['S Rating', 'Severity', 'Severity to Patient/User', 'Severity to Elcam', 'Severity to Manufacture'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'text_as_html': '<table><tr><td>S Rating</td><td>Severity</td><td>Severity to Patient/User</td><td>Severity to Elcam</td><td>Severity to Manufacture</td></tr><tr><td>1</td><td>Minor</td><td>All is fine up to small discomfort, minor damage in performance.</td><td>All is fine up to deviations in spec border.</td><td>Small effect on equipment or product, a few production hours loss.</td></tr><tr><td>2</td><td>Medium</td><td>Degradation in performance without harm.</td><td>Damage to image, do not meet spec.</td><td>Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss.</td></tr><tr><td>4</td><td>Severe</td><td>The part does not function but does not cause harm.</td><td>Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec.</td><td>Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss.</td></tr><tr><td>6</td><td>Severe - critical</td><td>The product does not function and causes injury or condition requiring medical treatment.</td><td>Severe impact to image, product will not meet the requirements of spec, market loss.</td><td>High deterioration in equipment or its operation severely affecting production or product functionality, several week losses.</td></tr><tr><td>8</td><td>Critical</td><td>Severe harm to patient: death, irreversible injury or condition or long term medical aid.</td><td>Low suit, market loss.</td><td>Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'ListItem', 'element_id': '803f3f9e5f4375827842aab91b3893e8', 'text': 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '63738466fb636f4834b25c937279df28', 'text': 'Degree of Detectability (D) – Relevant mainly to Process risks: ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Detectability (D) – Relevant mainly to Process risks:', 'Degree of Detectability (D) – Relevant mainly to Process risks:'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'Table', 'element_id': '7c0eaa7f5ad8ff06039efa1a771de75a', 'text': 'D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.', 'metadata': {'emphasized_text_contents': ['D Rating', 'Defect Detection'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'text_as_html': '<table><tr><td>D Rating</td><td>Defect Detection</td></tr><tr><td>1</td><td>Defect, if occurred, will always be detected at Elcam during production.</td></tr><tr><td>2</td><td>Defect, if occurred, will occasionally be detected at Elcam during production.</td></tr><tr><td>3</td><td>Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user).</td></tr><tr><td>4</td><td>Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'Title', 'element_id': '696e7ceba9f764cd2b35e82a4b47037e', 'text': 'RPN calculation:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['RPN calculation:'], 'emphasized_text_tags': ['i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '158f7513186e2f0d8d91159d90271fc3'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'c077b1d1e5fc540e61683cfaf1097496', 'text': 'The calculation of the Risk Priority Number (RPN) is done by multiplying the risk values:         (S x P) or (S x P x D).', 'metadata': {'category_depth': 0, 'emphasized_text_contents': [':', '(S x P)', '(S x P x D)'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '30e9d0edca44e21fdb50d6526ab2e7b5', 'text': 'According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). ', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ade2499d3d45315fa052e2da283c2813', 'text': 'Risk Priority Levels:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Risk Priority Levels:', 'Risk Priority Levels:'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'Table', 'element_id': '0de976617c7debc6f9fed1679c647643', 'text': '(S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P)<32 (Yellow) Medium (ALARP/AFAP*) 32≤(S*P) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P) value', 'Color', 'Risk priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'text_as_html': '<table><tr><td>(S*P) value</td><td>Color</td><td>Risk priority Level</td></tr><tr><td>(S*P)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P)&lt;32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32≤(S*P)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '2570a53cfc5e28b047fc58062cb2f73f', 'text': 'Or', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'Table', 'element_id': '61ddba95e0e4540adea9841791206fab', 'text': '(S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P*D) value', 'Color', 'Risk Priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'text_as_html': '<table><tr><td>(S*P*D) value</td><td>Color</td><td>Risk Priority Level</td></tr><tr><td>(S*P*D)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P*D)≤32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32&lt;(S*P*D)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4fce26d86c00a21a70cdba64a18eb256', 'text': 'Green area – Low rated risks.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Green area –'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a1c6b775ffcac9edde079c5db2e806ee', 'text': 'Yellow area – Medium rated risks. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Yellow area'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '5bf43bdd7f8e599bee7eb1bd29a5d7a9', 'text': 'Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '976e4b08bea18a165a12c33396a932b2', 'text': 'Red area – High rated risk, additional actions should be taken to reduce this risk. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Red area'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '78958f336fb75905a4a47d3d9f650052', 'text': 'Risk Control:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['Risk Control:', 'Risk Control:'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '25f66022543b62c1f06a28fda41ec98c', 'text': 'For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'c3143da565f2d49ed81908dd75841c71', 'text': 'The risk control measures should be one or more of the following options in the priority order listed:', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '380945897365e570a1410322c8fe0187', 'text': 'Inherent safety by design', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '151b2e88881398ff3ba07370f3719adc', 'text': 'Protective measures in the product itself or in the manufacturing process.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '89348c72dc16976eff780dc5916604c2', 'text': 'Information for safety', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '04c150c29af0d2b8766f851982306b4a', 'text': 'Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['defining', 'Implementation', 'Residual Risk Evaluation', 'Risk to Benefit Analysis', 'Risks arising from the risk control measures'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7ce495c9f1fb0b4a366046816d544f7c', 'text': 'At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Acceptability of the Overall Residual Risk'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': 'ba97666af1b4ca718d719b482599333c', 'text': 'Production & Post-production Information:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['Production & Post-production Information:', 'Production & Post-production Information:'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '36be94a292cdc963516d1a3c148eef7f', 'text': \"After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\", 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': 'ce18c183a5b491725461beef790b6d5f', 'text': 'Verification plan', 'metadata': {'category_depth': 1, 'emphasized_text_contents': ['Verification plan'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': 'ee28d213fb70ed40523e617a503c2d3a', 'text': 'After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '8cb74c50a405bc678979321010eff8d5', 'text': 'The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '02139289fe7cc035e23ee6c82f612049', 'text': 'Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '0f517165f8ba649c952e995122ea5303', 'text': 'Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '075a08183d90dc874540da47f923a2fc', 'text': 'Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '70fae328d212d90580dfe2b7b240c070', 'text': 'Allocation of responsibilities:', 'metadata': {'category_depth': 1, 'emphasized_text_contents': ['Allocation of responsibilities:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '075a08183d90dc874540da47f923a2fc'}}\n",
      "{'type': 'ListItem', 'element_id': 'ef4f67478ba265b95fba5dc6b76425d3', 'text': 'Responsibility for assuring that the risk management activities are done is by the Project Manager.', 'metadata': {'category_depth': 2, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '70fae328d212d90580dfe2b7b240c070'}}\n",
      "{'type': 'ListItem', 'element_id': '533dbddef0d08ef4d0d1a0fde15df62a', 'text': 'Person In charge for Risk Management activities execution: Quality Engineer in R&D.', 'metadata': {'category_depth': 2, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '70fae328d212d90580dfe2b7b240c070'}}\n",
      "{'type': 'ListItem', 'element_id': '05e5b161747502079e46a74da90ebf27', 'text': 'Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.', 'metadata': {'category_depth': 2, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '70fae328d212d90580dfe2b7b240c070'}}\n",
      "{'type': 'ListItem', 'element_id': '0c9fb3cfaece3f853908d5de78d5c5df', 'text': 'Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.', 'metadata': {'category_depth': 2, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '70fae328d212d90580dfe2b7b240c070'}}\n",
      "{'type': 'ListItem', 'element_id': 'c2ab3769fd9eab3afc9324dc3b66cc18', 'text': 'Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.', 'metadata': {'category_depth': 2, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '70fae328d212d90580dfe2b7b240c070'}}\n",
      "{'type': 'ListItem', 'element_id': 'd49a7eddfe2181802bd88a5e1cc69aea', 'text': 'Documenting Risk Management Process', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Documenting Risk Management Process'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'b1dff9fea040e290a5a733edbea16c52', 'text': \"The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\", 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'bfc37f34920f89a71518c4f7f401e34a', 'text': 'Risk general management documents related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '5224872366d6f87cc795a68d66d2638b', 'text': 'Summary', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Summary'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4006badbfc4419ea2a30ec231f8facaf', 'text': 'This document outlines the risk management activities for all DPT modification projects. It determines the scales of rating them and the acceptance criteria. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '4e08595052b0f67641554fbddc2ffc2b', 'text': 'Document Revision Control:', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'Table', 'element_id': 'f935e4691ccdf69b266ad78ae775e72c', 'text': 'Revision History Tracking: Date: Revision 0- first release 19-Nov-2008 Revision A - Overall review and updates 30-Dec-2014 Revision B - Updating document format. Adding definitions of ALARP and AFAP to section 3. Updating Risk evaluation definitions in section 4.1.2.according to the new version of annexes 5, 7 and 8 of SOP 3-01-21. Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks) and Updating location of general risk documents (in the EPDM system). 12-Jan-2017', 'metadata': {'emphasized_text_contents': ['Revision History Tracking:', '-'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'text_as_html': '<table><tr><td>Revision History Tracking:</td><td>Date:</td></tr><tr><td>Revision 0- first release</td><td>19-Nov-2008</td></tr><tr><td>Revision A - Overall review and updates</td><td>30-Dec-2014</td></tr><tr><td>Revision B - Updating document format. Adding definitions of ALARP and AFAP to section 3. Updating Risk evaluation definitions in section 4.1.2.according to the new version of annexes 5, 7 and 8 of SOP 3-01-21. Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks) and Updating location of general risk documents (in the EPDM system).</td><td>12-Jan-2017</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'ListItem', 'element_id': '1ec589340e9a6bc6f815527ce3f305fd', 'text': 'Review and approval:', 'metadata': {'category_depth': 0, 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'Table', 'element_id': '5e6d1b33815049b428a0fcfb32bc1d8a', 'text': 'Written by: Name Date Signature QA Eng. - - -', 'metadata': {'emphasized_text_contents': ['Written by:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'text_as_html': '<table><tr><td>Written by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>QA Eng.</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng', 'deu'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'Table', 'element_id': 'c4a958d3a564936072c673adce87a62d', 'text': 'Reviewed & Approved by: Name Date Signature R&D Director /VP - - - VP of QA & RA/ QA Manager R&D - - -', 'metadata': {'emphasized_text_contents': ['Reviewed & Approved by:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP- Disposable Pressure Transducer modifications.doc', 'text_as_html': '<table><tr><td>Reviewed &amp; Approved by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>R&amp;D Director /VP</td><td>-</td><td>-</td><td>-</td></tr><tr><td>VP of QA &amp; RA/ QA Manager R&amp;D</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '696e7ceba9f764cd2b35e82a4b47037e'}}\n",
      "{'type': 'Header', 'element_id': '5b0df07560e1d30739828323fba94b7c', 'text': '3-01-21  SOP 4  Appendix Appendix status - released Revision  5 Valid from \\u200f25/12/2016 Product/s name Closed Stopcock & MRVLS Document status Under Edit Author - Title Revision B Risk Management Plan Release Date - Document# Doc-075342 Page 9 of 9', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'header_footer_type': 'primary', 'languages': ['eng'], 'filetype': 'application/msword'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '330213204eac2a833523df97e8fac71a', 'text': 'Company: Elcam Medical', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Company: Elcam Medical'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '63b29346008edda146e7be6deed8e7a1', 'text': 'Product Description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Product Description:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '3a7ed0bf96f7495c2dccd2c8c36ee0dd', 'text': 'Elcam Closed Swabable Stopcocks (CSTP) and Minimal Residual Volume Luer-activated Swabable-stopcock (MRVLS) stopcocks are indicated for fluid flow directional control and for providing access port(s) for administration of solutions. Typical uses include pressure monitoring, intravenous fluid administration and transfusion.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Closed Swabable Stopcocks', 'Minimal Residual Volume Luer-activated Swabable-stopcock'], 'emphasized_text_tags': ['i', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'ca13383c2578084eb987402f7a3794e0', 'text': 'The Closed Swabable Stopcock includes an addition of a component that', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Closed Swabable Stopcock'], 'emphasized_text_tags': ['i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '19eade1c5d5434b50a4342e5022e1e5c', 'text': 'functions as a closed luer-activated valve.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a0827d108f34b797f0fdeeaa54f40ddb', 'text': 'The MRVLS feature, is an additional option that can be added to the Closed Swabable', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6735936cad3a7c08f3b480d851dd0891', 'text': 'Stopcock and provides a stopcock with a minimal residual volume.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'c94161bf36dc83efb9a4845dcb4d134e', 'text': 'This Risk management plan covers all risk management activities required for CSTP and MRVLS projects as well as their design change projects.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0eba4901244a24b3d176998cce59f1f4', 'text': 'Their lifecycle stages are divided to:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '6b4da4ecb63d3a8297bc7235b6730db1', 'text': 'project initiation', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '7cc537318c4038983639c1ea285d49f3', 'text': 'Design Planning', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '2b88982e322cdbf7e21a789852015aa2', 'text': 'Design Input', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '387e5ff8310822f8aefcff1856f12d4d', 'text': 'Design Output', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '80b8e6d4632c0361122af8c290491003', 'text': 'Design Verification & Validation', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '1054f0208d345f9814d7eeffcd8eddb9', 'text': 'Process Validation', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '3c55f88afcf886ad7611a068dfe5a18f', 'text': 'Transfer to production', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '113e363d5df2678ff7f8c2c6aa81ef3c', 'text': 'Production & Post marketing', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': 'b274c892a19d6792fec9546efb5b76f7', 'text': 'First Risk review meeting shall be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '0b56013e2f5578b4eedc2dbd1e10560f', 'text': 'Purpose:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Purpose:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '88ea56bc95eae259487d3e16886c2d8d', 'text': 'The purpose of this document is planning the risk management process for the Closed Stopcock and MRVLS family of products.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': '3bbfb35118c430312cf177751324b3d1', 'text': 'Definitions:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Definitions:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '24f85eb831861ca1933cd1d57a990c4f', 'text': 'FMEA: Failure Mode and Effect Analysis.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'd965230c945e9ec0de8ab6917809d6ab', 'text': 'Harm: physical injury or damage to the health of people, or damage to property or the environment.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '27e2b639e33d76d439844078024cc169', 'text': 'Hazard: potential source of harm. ', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9f122a84185684c9a800418118102314', 'text': 'Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ac89952805da01b7df1a05b02373ed68', 'text': 'Risk: combination of the probability of occurrence of harm and the severity of that harm.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '0a2f173be4bbe14c473f8ca9a34dac55', 'text': 'RPN: Risk Priority number, Multiply of Severity*Probability*Detectability.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'e8dcecc744ee7536d4bb414c90f28106', 'text': 'ALARP:  As Low As Reasonably Possible.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '81b25ebffaee0f33b435cf7d6e43251e', 'text': 'AFAP:  As Far as Possible.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng', 'por'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': 'ffef27139599ca4211bd4121e6cbc2a3', 'text': 'Method:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Method:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'a0537d41b954a2b34befe031498069c0', 'text': '4.1. Risk Management Process description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.', 'Risk Management Process description:'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['fra', 'eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '99a2c7e42e7cfd211ec76d9f14043e1b', 'text': 'Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam\\'s SOP# 03-01-21.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '66bb4a1df89be34d52f2793882975b99', 'text': 'The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Risk Analysis', 'Risk Evaluation', 'Risk Control', 'Production & Post Production information.'], 'emphasized_text_tags': ['b', 'b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a635a7bc088e6dfc6e3703558a1cb969', 'text': '(The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['FMEA'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '50cb11f4760929dbe0456fac742b3bfb', 'text': \"The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\", 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '27f364bc9d7c1d3b2e31d598df337a39', 'text': '4.1.1. Risk Analysis:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.1.', 'Risk Analysis', 'Risk Analysis', ':'], 'emphasized_text_tags': ['b', 'b', 'i', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '3dd525dd3a3cb8fe482bd07524d103ed', 'text': 'First step is listing the intended use or purpose of the product and its characteristics related to its safety. ', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a11ef3e6a9d55ab00e80a6ebf3d30458', 'text': 'Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': [', identifying the known or foreseeable hazards and hazardous situations', 'causes', 'risks'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '9d10defd4f16d32837fdb92943fde217', 'text': '4.1.2. Risk Evaluation:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.2.', 'Risk Evaluation:', 'Risk Evaluation:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7db21d39c917f1447ec6564cb1c26f0b', 'text': 'The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['probability', '(P)', 'severity (S)', 'detectability (D)', 'RPN', 'acceptance criteria'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': '95a2a4b2c04549ebbb2ca6680ca536f4', 'text': 'Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['P', 'S', 'D'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '7b0efe12dda08983a131a24e784f81e0', 'text': 'Probability of occurrence (P):  ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Probability of occurrence', 'Probability of occurrence', '(', 'P', 'P'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'Table', 'element_id': 'c6ac5042639fec841558fc89dcef47e9', 'text': 'Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:100,000 - 1:1,000,000 Low probability, rare occurrence 4 1:100,000 - 1:10,000 Will occur several times 6 1:100 - 1:10,000 Will occur several times 8 More than 1:100 High probability, likely to occur frequently', 'metadata': {'emphasized_text_contents': ['Value', 'Probability for occurrence', 'Verbal description for probability'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'text_as_html': '<table><tr><td>Value</td><td>Probability for occurrence</td><td>Verbal description for probability</td></tr><tr><td>1</td><td>Less than 1 in 1,000,000</td><td>Evidence that will not occur</td></tr><tr><td>2</td><td>1:100,000 - 1:1,000,000</td><td>Low probability, rare occurrence</td></tr><tr><td>4</td><td>1:100,000 - 1:10,000</td><td>Will occur several times</td></tr><tr><td>6</td><td>1:100 - 1:10,000</td><td>Will occur several times</td></tr><tr><td>8</td><td>More than 1:100</td><td>High probability, likely to occur frequently</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '12569b0f9f60f8e5a81695abc5bb2089', 'text': 'Degree of Severity (S): ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Severity', 'Degree of Severity', '(', 'S', 'S'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'Table', 'element_id': '24bb91f4fc0a952cb0f029fc0bc5c66e', 'text': 'S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.', 'metadata': {'emphasized_text_contents': ['S Rating', 'Severity', 'Severity to Patient/User', 'Severity to Elcam', 'Severity to Manufacture'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'text_as_html': '<table><tr><td>S Rating</td><td>Severity</td><td>Severity to Patient/User</td><td>Severity to Elcam</td><td>Severity to Manufacture</td></tr><tr><td>1</td><td>Minor</td><td>All is fine up to small discomfort, minor damage in performance.</td><td>All is fine up to deviations in spec border.</td><td>Small effect on equipment or product, a few production hours loss.</td></tr><tr><td>2</td><td>Medium</td><td>Degradation in performance without harm.</td><td>Damage to image, do not meet spec.</td><td>Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss.</td></tr><tr><td>4</td><td>Severe</td><td>The part does not function but does not cause harm.</td><td>Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec.</td><td>Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss.</td></tr><tr><td>6</td><td>Severe - critical</td><td>The product does not function and causes injury or condition requiring medical treatment.</td><td>Severe impact to image, product will not meet the requirements of spec, market loss.</td><td>High deterioration in equipment or its operation severely affecting production or product functionality, several week losses.</td></tr><tr><td>8</td><td>Critical</td><td>Severe harm to patient: death, irreversible injury or condition or long term medical aid.</td><td>Low suit, market loss.</td><td>Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'ListItem', 'element_id': 'aec41a6a42cc253684301519cd89acf2', 'text': 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '27854aa591417d26b8c8c846a6381f4f', 'text': 'Degree of Detectability (D): ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Detectability (D):', 'Degree of Detectability (D):'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'Table', 'element_id': '331c2e9462f066298d8088f8251af7cf', 'text': 'D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.', 'metadata': {'emphasized_text_contents': ['D Rating', 'Defect Detection'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'text_as_html': '<table><tr><td>D Rating</td><td>Defect Detection</td></tr><tr><td>1</td><td>Defect, if occurred, will always be detected at Elcam during production.</td></tr><tr><td>2</td><td>Defect, if occurred, will occasionally be detected at Elcam during production.</td></tr><tr><td>3</td><td>Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user).</td></tr><tr><td>4</td><td>Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'Title', 'element_id': '880b28ba6acfbdb310717e9f4d6ae516', 'text': 'RPN calculation:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['RPN calculation:'], 'emphasized_text_tags': ['i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '5b0df07560e1d30739828323fba94b7c'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'b76fc42bd78a39d9949b18842d5ac7a6', 'text': 'The calculation of the Risk Priority Number (RPN) is done by multiplying the risk analysis values:            (S x P) or (S x P x D).', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['(S x P)', '(S x P x D)'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '76b225e52204526b0ed54630aea7f03b', 'text': 'According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). ', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'b4409387e593c9c28a1f652b935a36c5', 'text': 'Risk Priority Levels:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'Table', 'element_id': '84f322329110c2bfc0cb5cbb7bd69262', 'text': '(S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P)<32 (Yellow) Medium (ALARP/AFAP*) 32≤(S*P) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P) value', 'Color', 'Risk priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'text_as_html': '<table><tr><td>(S*P) value</td><td>Color</td><td>Risk priority Level</td></tr><tr><td>(S*P)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P)&lt;32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32≤(S*P)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '93f937b0bf96f9d8734a914b54d98b7d', 'text': 'Or', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'Table', 'element_id': 'cbc47f4398253d86d02914faa94c0c5f', 'text': '(S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P*D) value', 'Color', 'Risk Priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'text_as_html': '<table><tr><td>(S*P*D) value</td><td>Color</td><td>Risk Priority Level</td></tr><tr><td>(S*P*D)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P*D)≤32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32&lt;(S*P*D)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '68d4e45ae89111597d8e15c957e7329e', 'text': 'Green area – Low rated risks.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Green area –'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'b71b11d37ac4818277dceba76f0d5a07', 'text': 'Yellow area – Medium rated risks. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Yellow area'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '3f6c430b0fff2881a861bbc85e45a1a7', 'text': 'Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['*'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'de4c66ca979a3a643e7c3c5cce579e59', 'text': 'Red area – High rated risk, additional actions should be taken to reduce this risk. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Red area'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '2ecf93435668cfa72aee540db49ffca9', 'text': '4.1.3. Risk Control:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.3.', 'Risk Control:', 'Risk Control:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'da5519282ab27f92c006bcbe6b32b9de', 'text': 'For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '2106e8fb60df1a0d2b76091d4c370af5', 'text': 'The risk control measures should be one or more of the following options in the priority order listed:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '6c8df1bc24d70fc6e9f073368688111d', 'text': 'Inherent safety by design', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '20e5f4600c91bdeb08194c29d8ea6efd', 'text': 'Protective measures in the product itself or in the manufacturing process.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '344664b1857eece25e0baf1896008d64', 'text': 'Information for safety', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '14beeb6befc54571e8dc38d1b378d8d0', 'text': 'Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['defining', 'Implementation', 'Residual Risk Evaluation', 'Risk to Benefit Analysis', 'Risks arising from the risk control measures'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e7b74064ea6c580c4531b19ed92f82ae', 'text': 'At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Acceptability of the Overall Residual Risk'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '8426fe42c7d719514c7837d86e221f87', 'text': '4.1.4. Production & Post-production Information:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.4.', 'Production & Post-production Information:', 'Production & Post-production Information:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'af60972bb1318e67f9bf910d614c0001', 'text': \"After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\", 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '280a7b7d051ca00ea7488f3bc36a4047', 'text': '4.2. Verification plan', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.2. Verification plan'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '03e76d5674ef10942c2dc03762fc8d28', 'text': 'After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '8e73ddadd23aeba7c7b7aa7981d932d9', 'text': 'The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '05e1f1bfe320d8fbc087b6719339eebb', 'text': 'Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '1c899022591a8bb762ded2505aa83cd0', 'text': 'Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '444494d5c4629ae7b1d6bfdfe0d95431', 'text': 'Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'a7286afa8754f9196933eabf82f99568', 'text': '4.3. Allocation of responsibilities:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3. Allocation of responsibilities:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '648b6344b18be44d584ff103579951e7', 'text': '4.3.1. Responsibility for assuring that the risk management activities are done is by the Project Manager.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.1.'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '6601d5b8456a20c363a650985f7010b1', 'text': '4.3.2. Person In charge for Risk Management activities execution: Quality Engineer in R&D.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.2.'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '402bbe860104598f54387042e3ca0af0', 'text': '4.3.3. Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.3.'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '8276d7fdd0cb78872b19ce9de1d28392', 'text': '4.3.4. Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.4'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '00150c2f40f426f037853e4736325eda', 'text': '4.3.5. Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.5'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': 'a118a2b612eced0fd05e6a51b3fd2604', 'text': 'Documenting Risk Management Process', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Documenting Risk Management Process'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'ba266a0fe88087ac07567fe9afa1148e', 'text': \"The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\", 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '1c83cfd24b4630252814412d1114ae90', 'text': 'Risk general management documents related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': 'feacf270371c2842890ccd077e5c484d', 'text': 'Summary', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Summary'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'NarrativeText', 'element_id': '8e2cf07ffc655b0f09b60b0be126e425', 'text': 'This document outlines the risk management activities for CSTP and MRVLS family of products. It determines the scales of rating them and the acceptance criteria. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '38e22869a43ce66df911aaa2f7f1aa69', 'text': 'Document Revision Control:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'Table', 'element_id': '687547dc23bc9f7e4867c7fe38dc2295', 'text': 'Revision History Tracking: Date: Revision 0- first version 5-July-2012 Revision A – update of referenced standards and definition of ALARP/AFAP. 16-Mar-2014 Revision B – Updating document format; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 \"Responsibilities\" and 4.3. \"Allocation of responsibilities\". 27-Dec-2016', 'metadata': {'emphasized_text_contents': ['Revision History Tracking:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'text_as_html': '<table><tr><td>Revision History Tracking:</td><td>Date:</td></tr><tr><td>Revision 0- first version</td><td>5-July-2012</td></tr><tr><td>Revision A – update of referenced standards and definition of ALARP/AFAP.</td><td>16-Mar-2014</td></tr><tr><td>Revision B – Updating document format; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 &quot;Responsibilities&quot; and 4.3. &quot;Allocation of responsibilities&quot;.</td><td>27-Dec-2016</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'ListItem', 'element_id': '216d45a896066794162a7e1a5f324b62', 'text': 'Review and approval:', 'metadata': {'category_depth': 0, 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'Table', 'element_id': '386276a6ef7fa3c52a643b2d917ebf73', 'text': 'Written by: Name Date Signature QA Eng. - - -', 'metadata': {'emphasized_text_contents': ['Written by:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'text_as_html': '<table><tr><td>Written by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>QA Eng.</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng', 'deu'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'Table', 'element_id': '35e315ece4bfdd07d647a58c44f70171', 'text': 'Reviewed & Approved by: Name Date Signature R&D Director /VP - - - VP of QA & RA/ QA Manager R&D - - -', 'metadata': {'emphasized_text_contents': ['Reviewed & Approved by:'], 'emphasized_text_tags': ['b'], 'filename': 'RMP - Closed Stopcock & MRVLS.doc', 'text_as_html': '<table><tr><td>Reviewed &amp; Approved by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>R&amp;D Director /VP</td><td>-</td><td>-</td><td>-</td></tr><tr><td>VP of QA &amp; RA/ QA Manager R&amp;D</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '880b28ba6acfbdb310717e9f4d6ae516'}}\n",
      "{'type': 'Header', 'element_id': 'f98357608bd935cc707723ddc9d002dc', 'text': 'SOP 3-01-21 4  Appendix Appendix status - released Revision  7 Valid from \\u200f20/04/2017 Product/s name Closed Stopcock & MRVLS Document status Under Edit Author - Title Revision C Risk Management Plan Release Date - Document# Doc-081935 Page 8 of 8', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'header_footer_type': 'primary', 'languages': ['eng'], 'filetype': 'application/msword'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '639d3c3bdfee63af9db1447bad31f087', 'text': 'Company: Elcam Medical', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Company: Elcam Medical'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '9e0073eec0648652c0644bb6baa3cbe2', 'text': 'Product Description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Product Description:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': '576e8c3659e5f46d30b4186a7cd0f793', 'text': 'Elcam Closed Swabable Stopcocks (CSTP) and Minimal Residual Volume Luer-activated Swabable-stopcock (MRVLS) stopcocks are indicated for fluid flow directional control and for providing access port(s) for administration of solutions. Typical uses include pressure monitoring, intravenous fluid administration and transfusion.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Closed Swabable Stopcocks', 'Minimal Residual Volume Luer-activated Swabable-stopcock'], 'emphasized_text_tags': ['i', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a29c5138c9c684b3d6aee3645db74fe6', 'text': 'The Closed Swabable Stopcock includes an addition of a component that', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Closed Swabable Stopcock'], 'emphasized_text_tags': ['i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'f7e4ff58a7f85c321f41db66fb86b74a', 'text': 'functions as a closed luer-activated valve.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'fe3ffd9275def4fda73efd27d7c1f790', 'text': 'The MRVLS feature, is an additional option that can be added to the Closed Swabable', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': '93eb2f25c5c8cf36e38caafeb626b573', 'text': 'Stopcock and provides a stopcock with a minimal residual volume.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'f67cfec2b77e128e5be4748fbb15e534', 'text': 'This Risk management plan covers all risk management activities required for CSTP and MRVLS projects as well as their design change projects.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'cfbe2bb46d1fc029e0b1312dfaded2e1', 'text': 'Their lifecycle stages are divided to:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '8ec5bbec7ec7c623ce2fab29acacb95c', 'text': 'project initiation', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '55fd939adcaf4a3765adf77e850924a8', 'text': 'Design Planning', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': 'ecb13195816a10cb2f7ef68668c4ee8e', 'text': 'Design Input', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': 'abcbdb38ba180dbc31ea25b45dbb2969', 'text': 'Design Output', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '4075e32ecf54f919fc1b764ad0d66447', 'text': 'Design Verification & Validation', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '7f804b20a8ea5e492d6e489bbeea0cec', 'text': 'Process Validation', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '0c22adbf43746ca483ff64ecbb7cdf58', 'text': 'Transfer to production', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': 'f01af0eedd49fe6f3296a5f51a57fd25', 'text': 'Production & Post marketing', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': 'cdc28514f28914b51ec699e1d3b05d3c', 'text': 'First Risk review meeting shall be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': 'c59b0bf6f76722e0dd0ccc9687016c6f', 'text': 'Purpose:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Purpose:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a650207e8535084f04ed37213c5baa82', 'text': 'The purpose of this document is planning the risk management process for the Closed Stopcock and MRVLS family of products.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '634bcf0d758b47ffcbc5cdcdd12afe8e', 'text': 'Definitions:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Definitions:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '513242db5386ed00df0b8ab4bcc2c667', 'text': 'FMEA: Failure Mode and Effect Analysis.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '9afa2201fddb19f49b7f283e1c3a90e2', 'text': 'Harm: physical injury or damage to the health of people, or damage to property or the environment.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '380f09defe27457d2af30a9549f0b4eb', 'text': 'Hazard: potential source of harm. ', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'c29d8529bede913c5d33f62d9d218976', 'text': 'Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '69ddfa0c98f1da5df809f0911dfffdfb', 'text': 'Risk: combination of the probability of occurrence of harm and the severity of that harm.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '0198ec5f43325c3deacc91850b8ac090', 'text': 'RPN: Risk Priority number, Multiply of Severity*Probability*Detectability.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'b126efd88d2bbf97a13b6c57c3f0e459', 'text': 'ALARP:  As Low As Reasonably Possible.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '73f485f64228db621f6b94c1d059c948', 'text': 'AFAP:  As Far as Possible.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng', 'por'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '47b7b15db55e6410b43d227ec9fd70f0', 'text': 'Method:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Method:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'adfa18d7bc5ede76bf5632508b8f6dc5', 'text': '4.1. Risk Management Process description:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.', 'Risk Management Process description:'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['fra', 'eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a07ea0dbb55cc13a75e995f74f0d1c60', 'text': 'Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam\\'s SOP# 03-01-21.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a78384c6f6b1c3d9d1fd063e36164e89', 'text': 'The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Risk Analysis', 'Risk Evaluation', 'Risk Control', 'Production & Post Production information.'], 'emphasized_text_tags': ['b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'ae7627550fe20eece3b98c81ad57f9f9', 'text': '(The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['FMEA'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'b82394a2cc96a22cc96aad2913737c0e', 'text': \"The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\", 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'd937ee2937de5d6c2d10af6657d14e8e', 'text': '4.1.1. Risk Analysis:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.1.', 'Risk Analysis', 'Risk Analysis', ':'], 'emphasized_text_tags': ['b', 'b', 'i', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'ea24a9448911dd2a043a3d6a6d4cfc67', 'text': 'First step is listing the intended use or purpose of the product and its characteristics related to its safety. ', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': '49a227e081f90a19943d36baa61af339', 'text': 'Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': [', identifying the known or foreseeable hazards and hazardous situations', 'causes', 'risks'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '57d7fcbb094e2415abc3dd5563c18bb7', 'text': '4.1.2. Risk Evaluation:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.2.', 'Risk Evaluation:', 'Risk Evaluation:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6ebd8cfcfa8dffee7876a6e5c7410a9b', 'text': 'The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['probability', '(P)', 'severity (S)', 'detectability (D)', 'RPN', 'acceptance criteria'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'fb563525eab374404620a00f353bcada', 'text': 'Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['P', 'S', 'D'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'c0403e724991509f2283b46b75d70e0b', 'text': 'Probability of occurrence (P):  ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Probability of occurrence', 'Probability of occurrence', '(', 'P', 'P'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'Table', 'element_id': '6b6ab69625301e0b63366f2e28496d54', 'text': 'Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:10,000 - 1:1,000,000 Low probability, rare occurrence 4 1:1,000 - 1:10,000 Will occur several times 6 1:100 - 1:1,000 Will occur several times, often 8 More than 1:100 High probability, likely to occur frequently', 'metadata': {'emphasized_text_contents': ['Value', 'Probability for occurrence', 'Verbal description for probability'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'text_as_html': '<table><tr><td>Value</td><td>Probability for occurrence</td><td>Verbal description for probability</td></tr><tr><td>1</td><td>Less than 1 in 1,000,000</td><td>Evidence that will not occur</td></tr><tr><td>2</td><td>1:10,000 - 1:1,000,000</td><td>Low probability, rare occurrence</td></tr><tr><td>4</td><td>1:1,000 - 1:10,000</td><td>Will occur several times</td></tr><tr><td>6</td><td>1:100 - 1:1,000</td><td>Will occur several times, often</td></tr><tr><td>8</td><td>More than 1:100</td><td>High probability, likely to occur frequently</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '676b6004b16de8bda1fd08f69ec806f5', 'text': 'Degree of Severity (S): ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Severity', 'Degree of Severity', '(', 'S', 'S'], 'emphasized_text_tags': ['b', 'i', 'i', 'b', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'Table', 'element_id': '195846575d9316a61a9c60e489317e7b', 'text': 'S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.', 'metadata': {'emphasized_text_contents': ['S Rating', 'Severity', 'Severity to Patient/User', 'Severity to Elcam', 'Severity to Manufacture'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'text_as_html': '<table><tr><td>S Rating</td><td>Severity</td><td>Severity to Patient/User</td><td>Severity to Elcam</td><td>Severity to Manufacture</td></tr><tr><td>1</td><td>Minor</td><td>All is fine up to small discomfort, minor damage in performance.</td><td>All is fine up to deviations in spec border.</td><td>Small effect on equipment or product, a few production hours loss.</td></tr><tr><td>2</td><td>Medium</td><td>Degradation in performance without harm.</td><td>Damage to image, do not meet spec.</td><td>Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss.</td></tr><tr><td>4</td><td>Severe</td><td>The part does not function but does not cause harm.</td><td>Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec.</td><td>Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss.</td></tr><tr><td>6</td><td>Severe - critical</td><td>The product does not function and causes injury or condition requiring medical treatment.</td><td>Severe impact to image, product will not meet the requirements of spec, market loss.</td><td>High deterioration in equipment or its operation severely affecting production or product functionality, several week losses.</td></tr><tr><td>8</td><td>Critical</td><td>Severe harm to patient: death, irreversible injury or condition or long term medical aid.</td><td>Low suit, market loss.</td><td>Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'ListItem', 'element_id': '15b1bffbb0f0b9417b090c7ff282dc75', 'text': 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.', 'Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '9d450f7761f34b05eee031ba1f65fdb1', 'text': 'Degree of Detectability (D) – Relevant mainly to Process risks: ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Degree of Detectability (D) – Relevant mainly to Process risks:', 'Degree of Detectability (D) – Relevant mainly to Process risks:'], 'emphasized_text_tags': ['b', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'Table', 'element_id': '6396fb71f8358b627db944b86466c04a', 'text': 'D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.', 'metadata': {'emphasized_text_contents': ['D Rating', 'Defect Detection'], 'emphasized_text_tags': ['b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'text_as_html': '<table><tr><td>D Rating</td><td>Defect Detection</td></tr><tr><td>1</td><td>Defect, if occurred, will always be detected at Elcam during production.</td></tr><tr><td>2</td><td>Defect, if occurred, will occasionally be detected at Elcam during production.</td></tr><tr><td>3</td><td>Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user).</td></tr><tr><td>4</td><td>Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'Title', 'element_id': '46ec9d75bc80beef467f594f1cfe64ed', 'text': 'RPN calculation:', 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['RPN calculation:'], 'emphasized_text_tags': ['i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': 'f98357608bd935cc707723ddc9d002dc'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'd84b2d58e94db578fb6342c619475427', 'text': 'The calculation of the Risk Priority Number (RPN) is done by multiplying the risk values:         (S x P) or (S x P x D).', 'metadata': {'category_depth': 0, 'emphasized_text_contents': [':', '(S x P)', '(S x P x D)'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '363df62d95e68c567a1a5f9fb1555e87', 'text': 'According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). ', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '7b9f87b57fa9460d73998480a2679e74', 'text': 'Risk Priority Levels:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'Table', 'element_id': '869c74619867f3feb486a94d3c86621c', 'text': '(S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P) ≤32 (Yellow) Medium (ALARP/AFAP*) 32< (S*P) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P) value', 'Color', 'Risk priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'text_as_html': '<table><tr><td>(S*P) value</td><td>Color</td><td>Risk priority Level</td></tr><tr><td>(S*P)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P) ≤32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32&lt; (S*P)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '81012bb84096b31356137236173c183d', 'text': 'Or', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'Table', 'element_id': 'b47b3c0a6e540b706720f6be7a45cd5c', 'text': '(S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High', 'metadata': {'emphasized_text_contents': ['(S*P*D) value', 'Color', 'Risk Priority Level'], 'emphasized_text_tags': ['b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'text_as_html': '<table><tr><td>(S*P*D) value</td><td>Color</td><td>Risk Priority Level</td></tr><tr><td>(S*P*D)≤8</td><td>(Green)</td><td>Low</td></tr><tr><td>8&lt;(S*P*D)≤32</td><td>(Yellow)</td><td>Medium (ALARP/AFAP*)</td></tr><tr><td>32&lt;(S*P*D)</td><td>(Red)</td><td>High</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '5ed12565a54d9c66edc3b1c8886396dc', 'text': 'Green area – Low rated risks.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Green area –'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'f9de5d0d32b8a44656e54fe398896f6d', 'text': 'Yellow area – Medium rated risks. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Yellow area'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '13506b4c0feab0296e5eee2d8b9870cd', 'text': 'Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '41febdffac346eb1015f8bbe5f86486d', 'text': 'Red area – High rated risk, additional actions should be taken to reduce this risk. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Red area'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '18f59a581fffca02290f1cd3440fac86', 'text': '4.1.3. Risk Control:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.3.', 'Risk Control:', 'Risk Control:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4146540f3e325d6373c6625610c6433d', 'text': 'For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e7b23142b0af1725e120c53d9e10f439', 'text': 'The risk control measures should be one or more of the following options in the priority order listed:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '0b41c93532fe2e5fd73c37e0a46ad006', 'text': 'Inherent safety by design', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '75fdb3411ad1a4b9220e64afd2315d6e', 'text': 'Protective measures in the product itself or in the manufacturing process.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '94416ad390106fcc625336a5700b4b9a', 'text': 'Information for safety', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '3355b9f4956d02ada2cefb6535d0ebd4', 'text': 'Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['defining', 'Implementation', 'Residual Risk Evaluation', 'Risk to Benefit Analysis', 'Risks arising from the risk control measures'], 'emphasized_text_tags': ['b', 'b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '31bbb2b11d1c860dc0a6c2c08d09a098', 'text': 'At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. ', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Acceptability of the Overall Residual Risk'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'b825f09ac927227d3c3787479807d371', 'text': '4.1.4. Production & Post-production Information:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.1.4.', 'Production & Post-production Information:', 'Production & Post-production Information:'], 'emphasized_text_tags': ['b', 'b', 'i'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '864de0548d4f706d25740c6bed6c022c', 'text': \"After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\", 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '270547bbed809d01fb9d6a92e6800f65', 'text': '4.2. Verification plan', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.2. Verification plan'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': 'c0a98b02a08a8084ad8a3179ca80ac71', 'text': 'After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '17369c0d294821cc9cc5424c59dea8b5', 'text': 'The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': 'f32d56a816b5f5858c3fd3f44e8767e4', 'text': 'Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '60d8379d39d326dc30009e4fad7e0803', 'text': 'Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '0a95dd6f56b0fd29d57add11e86e0de5', 'text': 'Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '398da00072c479797949a2baa51db134', 'text': '4.3. Allocation of responsibilities:', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3. Allocation of responsibilities:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '58dc07bd4f9f229955fb5c8970cbe01a', 'text': '4.3.1. Responsibility for assuring that the risk management activities are done is by the Project Manager.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.1.'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '11bcf239dc66a20377a857520db254ed', 'text': '4.3.2. Person In charge for Risk Management activities execution: Quality Engineer in R&D.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.2.'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '16bd7072a5de4d857e020cdc8b7410b4', 'text': '4.3.3. Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.3.'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '1f4f2d4415565dfb95ff02de4c4b339b', 'text': '4.3.4. Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.4'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '3f200bf759a1f0da542c39aadd558910', 'text': '4.3.5. Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['4.3.5'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': 'c617adb79a23642ca743ac4d39cb79b3', 'text': 'Documenting Risk Management Process', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Documenting Risk Management Process'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '8c30118dd146bedd8f3fa6b61918855c', 'text': \"The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 or 8 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\", 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0fb9f605f4028627052dd753c87e65c4', 'text': 'General Risk management documents (for family of products) related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system and using appendix 7 of SOP 3-01-21. ', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '46c0139ddf70d6e48eb3e9e96b525157', 'text': 'Summary', 'metadata': {'category_depth': 0, 'emphasized_text_contents': ['Summary'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'NarrativeText', 'element_id': '1be05e4c41d0eaba7fb80592c1c084d1', 'text': 'This document outlines the risk management activities for the CSTP and MRVLS family of products. It determines the scales of rating them and the Risk Priority Levels. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': 'd579f17be9129567cf91899c916f8324', 'text': 'Document Revision Control:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'Table', 'element_id': '7b2bd14544af079deba98293f5e60b11', 'text': 'Revision History Tracking: Date: Revision 0- first version 5-July-2012 Revision A – update of referenced standards and definition of ALARP/AFAP. 16-Mar-2014 Revision B – Updating document format; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 \"Responsibilities\" and 4.3. \"Allocation of responsibilities\". 27-Dec-2016 Revision C – Correcting Probability scales and Risk Priority Levels according latest version of Appendix 5, 7 and 8 of SOP 3-01-21. Adding guidance for using appendix 5, 7 and 8 of SOP 3-01-21 to \"Documenting Risk Management Process\" section. 17-May-2017', 'metadata': {'emphasized_text_contents': ['Revision History Tracking:'], 'emphasized_text_tags': ['b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'text_as_html': '<table><tr><td>Revision History Tracking:</td><td>Date:</td></tr><tr><td>Revision 0- first version</td><td>5-July-2012</td></tr><tr><td>Revision A – update of referenced standards and definition of ALARP/AFAP.</td><td>16-Mar-2014</td></tr><tr><td>Revision B – Updating document format; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 &quot;Responsibilities&quot; and 4.3. &quot;Allocation of responsibilities&quot;.</td><td>27-Dec-2016</td></tr><tr><td>Revision C – Correcting Probability scales and Risk Priority Levels according latest version of Appendix 5, 7 and 8 of SOP 3-01-21. Adding guidance for using appendix 5, 7 and 8 of SOP 3-01-21 to &quot;Documenting Risk Management Process&quot; section.</td><td>17-May-2017</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'ListItem', 'element_id': '236dcc2021d24a13b2414059db54956f', 'text': 'Review and approval:', 'metadata': {'category_depth': 0, 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'Table', 'element_id': '9a07ed8cb2791352e92addf64419d209', 'text': 'Written by: Name Date Signature QA Eng. - - -', 'metadata': {'emphasized_text_contents': ['Written by:', 'Name', 'Date', 'Signature'], 'emphasized_text_tags': ['b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'text_as_html': '<table><tr><td>Written by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>QA Eng.</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng', 'deu'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n",
      "{'type': 'Table', 'element_id': 'eb39588f4eb41b93adf292d056b6ef16', 'text': 'Reviewed & Approved by: Name Date Signature Chief Technology Officer /R&D Manager - - - Chief Quality & RA Officer/ QA Manager R&D - - -', 'metadata': {'emphasized_text_contents': ['Reviewed & Approved by:', 'Name', 'Date', 'Signature'], 'emphasized_text_tags': ['b', 'b', 'b', 'b'], 'filename': 'Risk Management Plan - CSTP & MRVLS לא לשימוש.doc', 'text_as_html': '<table><tr><td>Reviewed &amp; Approved by:</td><td>Name</td><td>Date</td><td>Signature</td></tr><tr><td>Chief Technology Officer /R&amp;D Manager</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Chief Quality &amp; RA Officer/ QA Manager R&amp;D</td><td>-</td><td>-</td><td>-</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/msword', 'parent_id': '46ec9d75bc80beef467f594f1cfe64ed'}}\n"
     ]
    }
   ],
   "source": [
    "for el in elements:\n",
    "    for e in el:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>element_id</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [type, element_id, text, metadata]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cols=['type','element_id','text','metadata']\n",
    "df=pd.DataFrame(columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>element_id</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Header</td>\n",
       "      <td>df32bb9499063731ae7c2a472c41b75d</td>\n",
       "      <td>3-01-21  SOP 4  Appendix Appendix status - rel...</td>\n",
       "      <td>{'category_depth': 0, 'filename': 'RMP - Bonde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UncategorizedText</td>\n",
       "      <td>11e96d58f19dcb0f91ee6f57e9131670</td>\n",
       "      <td>Company: Elcam Medical</td>\n",
       "      <td>{'category_depth': 0, 'emphasized_text_content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ListItem</td>\n",
       "      <td>5761d445000d8a3fbe516913c39b71e0</td>\n",
       "      <td>Product Description:</td>\n",
       "      <td>{'category_depth': 0, 'emphasized_text_content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>297a929bb065d15e8a587281927dcce7</td>\n",
       "      <td>The Bonded Manifolds family of products contai...</td>\n",
       "      <td>{'category_depth': 0, 'filename': 'RMP - Bonde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NarrativeText</td>\n",
       "      <td>daba200c1a05502b866d26a0844cf190</td>\n",
       "      <td>This Risk management plan covers all risk mana...</td>\n",
       "      <td>{'category_depth': 0, 'filename': 'RMP - Bonde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>ListItem</td>\n",
       "      <td>d579f17be9129567cf91899c916f8324</td>\n",
       "      <td>Document Revision Control:</td>\n",
       "      <td>{'category_depth': 0, 'filename': 'Risk Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Table</td>\n",
       "      <td>7b2bd14544af079deba98293f5e60b11</td>\n",
       "      <td>Revision History Tracking: Date: Revision 0- f...</td>\n",
       "      <td>{'emphasized_text_contents': ['Revision Histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>ListItem</td>\n",
       "      <td>236dcc2021d24a13b2414059db54956f</td>\n",
       "      <td>Review and approval:</td>\n",
       "      <td>{'category_depth': 0, 'filename': 'Risk Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Table</td>\n",
       "      <td>9a07ed8cb2791352e92addf64419d209</td>\n",
       "      <td>Written by: Name Date Signature QA Eng. - - -</td>\n",
       "      <td>{'emphasized_text_contents': ['Written by:', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Table</td>\n",
       "      <td>eb39588f4eb41b93adf292d056b6ef16</td>\n",
       "      <td>Reviewed &amp; Approved by: Name Date Signature Ch...</td>\n",
       "      <td>{'emphasized_text_contents': ['Reviewed &amp; Appr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type                        element_id  \\\n",
       "0               Header  df32bb9499063731ae7c2a472c41b75d   \n",
       "1    UncategorizedText  11e96d58f19dcb0f91ee6f57e9131670   \n",
       "2             ListItem  5761d445000d8a3fbe516913c39b71e0   \n",
       "3        NarrativeText  297a929bb065d15e8a587281927dcce7   \n",
       "4        NarrativeText  daba200c1a05502b866d26a0844cf190   \n",
       "..                 ...                               ...   \n",
       "444           ListItem  d579f17be9129567cf91899c916f8324   \n",
       "445              Table  7b2bd14544af079deba98293f5e60b11   \n",
       "446           ListItem  236dcc2021d24a13b2414059db54956f   \n",
       "447              Table  9a07ed8cb2791352e92addf64419d209   \n",
       "448              Table  eb39588f4eb41b93adf292d056b6ef16   \n",
       "\n",
       "                                                  text  \\\n",
       "0    3-01-21  SOP 4  Appendix Appendix status - rel...   \n",
       "1                               Company: Elcam Medical   \n",
       "2                                 Product Description:   \n",
       "3    The Bonded Manifolds family of products contai...   \n",
       "4    This Risk management plan covers all risk mana...   \n",
       "..                                                 ...   \n",
       "444                         Document Revision Control:   \n",
       "445  Revision History Tracking: Date: Revision 0- f...   \n",
       "446                               Review and approval:   \n",
       "447      Written by: Name Date Signature QA Eng. - - -   \n",
       "448  Reviewed & Approved by: Name Date Signature Ch...   \n",
       "\n",
       "                                              metadata  \n",
       "0    {'category_depth': 0, 'filename': 'RMP - Bonde...  \n",
       "1    {'category_depth': 0, 'emphasized_text_content...  \n",
       "2    {'category_depth': 0, 'emphasized_text_content...  \n",
       "3    {'category_depth': 0, 'filename': 'RMP - Bonde...  \n",
       "4    {'category_depth': 0, 'filename': 'RMP - Bonde...  \n",
       "..                                                 ...  \n",
       "444  {'category_depth': 0, 'filename': 'Risk Manage...  \n",
       "445  {'emphasized_text_contents': ['Revision Histor...  \n",
       "446  {'category_depth': 0, 'filename': 'Risk Manage...  \n",
       "447  {'emphasized_text_contents': ['Written by:', '...  \n",
       "448  {'emphasized_text_contents': ['Reviewed & Appr...  \n",
       "\n",
       "[449 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_list = []\n",
    "for element in elements:\n",
    "    for row in element:\n",
    "        rows_list.append({\n",
    "            'type': row['type'],\n",
    "            'element_id': row['element_id'],\n",
    "            'text': row['text'],\n",
    "            'metadata': row['metadata']\n",
    "        })\n",
    "df = pd.DataFrame(rows_list, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate text found in row 0: 3-01-21  SOP 4  Appendix Appendix status - released Revision  5 Valid from ‏25/12/2016 Product/s name Bonded Manifolds Document status Under Edit Author - Title Revision B Risk Management Plan Release Date - Document# Doc-075384 Page 8 of 8\n",
      "Duplicate text found in row 1: Company: Elcam Medical\n",
      "Duplicate text found in row 2: Product Description:\n",
      "Duplicate text found in row 3: The Bonded Manifolds family of products contains products that are alternative for Manifold-Monoblocks. They are 2,3 and 4 gang UV bonded manifold, LB and closed stopcocks.  \n",
      "Duplicate text found in row 4: This Risk management plan covers all risk management activities required for bonded manifolds development projects as well as their design change projects.\n",
      "Duplicate text found in row 5: Their lifecycle stages of such projects are divided to:\n",
      "Duplicate text found in row 6: project initiation\n",
      "Duplicate text found in row 7: Design Planning\n",
      "Duplicate text found in row 8: Design Input\n",
      "Duplicate text found in row 9: Design Output\n",
      "Duplicate text found in row 10: Design Verification & Validation\n",
      "Duplicate text found in row 11: Process Validation\n",
      "Duplicate text found in row 12: Transfer to production\n",
      "Duplicate text found in row 13: Production & Post marketing.\n",
      "Duplicate text found in row 14: First Risk review meeting shall be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project\n",
      "Duplicate text found in row 15: Purpose:\n",
      "Duplicate text found in row 16: The purpose of this document is planning the risk management process for the Bonded Manifold family of products.\n",
      "Duplicate text found in row 17: Definitions:\n",
      "Duplicate text found in row 18: FMEA: Failure Mode and Effect Analysis.\n",
      "Duplicate text found in row 19: Harm: physical injury or damage to the health of people, or damage to property or the environment.\n",
      "Duplicate text found in row 20: Hazard: potential source of harm. \n",
      "Duplicate text found in row 21: Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).\n",
      "Duplicate text found in row 22: Risk: combination of the probability of occurrence of harm and the severity of that harm.\n",
      "Duplicate text found in row 23: RPN: Risk Priority number\n",
      "Duplicate text found in row 24: ALARP:  As Low As Reasonably Possible.\n",
      "Duplicate text found in row 25: AFAP:  As Far as Possible.\n",
      "Duplicate text found in row 26: Method:\n",
      "Duplicate text found in row 27: 4.1. Risk Management Process description:\n",
      "Duplicate text found in row 28: Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam's SOP# 03-01-21.\n",
      "Duplicate text found in row 29: The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.\n",
      "Duplicate text found in row 30: (The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. \n",
      "Duplicate text found in row 31: The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\n",
      "Duplicate text found in row 32: 4.1.1. Risk Analysis:\n",
      "Duplicate text found in row 33: First step is listing the intended use or purpose of the product and its characteristics related to its safety. \n",
      "Duplicate text found in row 34: Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. \n",
      "Duplicate text found in row 35: 4.1.2. Risk Evaluation:\n",
      "Duplicate text found in row 36: The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. \n",
      "Duplicate text found in row 37: Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: \n",
      "Duplicate text found in row 38: Probability of occurrence (P):  \n",
      "Duplicate text found in row 39: Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:100,000 - 1:1,000,000 Low probability, rare occurrence 4 1:100,000 - 1:10,000 Will occur several times 6 1:100 - 1:10,000 Will occur several times 8 More than 1:100 High probability, likely to occur frequently\n",
      "Duplicate text found in row 40: Degree of Severity (S): \n",
      "Duplicate text found in row 41: S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.\n",
      "Duplicate text found in row 42: Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.\n",
      "Duplicate text found in row 43: Degree of Detectability (D): \n",
      "Duplicate text found in row 44: D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.\n",
      "Duplicate text found in row 45: RPN calculation:\n",
      "Duplicate text found in row 46: The calculation of the Risk Priority Number (RPN) is done by multiplying the risk analysis values:            (S x P) or (S x P x D).\n",
      "Duplicate text found in row 47: According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). \n",
      "Duplicate text found in row 48: Risk Priority Levels:\n",
      "Duplicate text found in row 49: (S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P)<32 (Yellow) Medium (ALARP/AFAP*) 32≤(S*P) (Red) High\n",
      "Duplicate text found in row 50: Or\n",
      "Duplicate text found in row 51: (S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High\n",
      "Duplicate text found in row 52: Green area – Low rated risks.\n",
      "Duplicate text found in row 53: Yellow area – Medium rated risks. \n",
      "Duplicate text found in row 54: Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.\n",
      "Duplicate text found in row 55: Red area – High rated risk, additional actions should be taken to reduce this risk. \n",
      "Duplicate text found in row 56: 4.1.3. Risk Control:\n",
      "Duplicate text found in row 57: For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.\n",
      "Duplicate text found in row 58: The risk control measures should be one or more of the following options in the priority order listed:\n",
      "Duplicate text found in row 59: Inherent safety by design\n",
      "Duplicate text found in row 60: Protective measures in the product itself or in the manufacturing process.\n",
      "Duplicate text found in row 61: Information for safety\n",
      "Duplicate text found in row 62: Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.\n",
      "Duplicate text found in row 63: At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. \n",
      "Duplicate text found in row 64: 4.1.4. Production & Post-production Information:\n",
      "Duplicate text found in row 65: After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\n",
      "Duplicate text found in row 66: 4.2. Verification plan\n",
      "Duplicate text found in row 67: After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).\n",
      "Duplicate text found in row 68: The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).\n",
      "Duplicate text found in row 69: Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.\n",
      "Duplicate text found in row 70: Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.\n",
      "Duplicate text found in row 71: Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.\n",
      "Duplicate text found in row 72: 4.3. Allocation of responsibilities:\n",
      "Duplicate text found in row 73: 4.3.1. Responsibility for assuring that the risk management activities are done is by the Project Manager.\n",
      "Duplicate text found in row 74: 4.3.2. Person In charge for Risk Management activities execution: Quality Engineer in R&D.\n",
      "Duplicate text found in row 75: 4.3.3. Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.\n",
      "Duplicate text found in row 76: 4.3.4. Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.\n",
      "Duplicate text found in row 77: 4.3.5. Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.\n",
      "Duplicate text found in row 78: Documenting Risk Management Process\n",
      "Duplicate text found in row 79: The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\n",
      "Duplicate text found in row 80: Risk general management documents related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system.\n",
      "Duplicate text found in row 81: Summary\n",
      "Duplicate text found in row 82: This document outlines the risk management activities for Bonded Manifold family of products. It determines the scales of rating them and the acceptance criteria. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.\n",
      "Duplicate text found in row 83: Document Revision Control:\n",
      "Duplicate text found in row 84: Revision History Tracking: Date: Revision 0- first version 5-July-2012 Revision A – update of referenced standards and definition of ALARP/AFAP in addition to Change of format and also having this document general for all customers. 16-Mar-2014 Revision B – Updating document format; Adding to section 1 timing along product lifecycle for risk management activities; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 \"Responsibilities\" and 4.3. \"Allocation of responsibilities\". 27-Dec-2016\n",
      "Duplicate text found in row 85: Review and approval:\n",
      "Duplicate text found in row 86: Written by: Name Date Signature QA Eng. - - -\n",
      "Duplicate text found in row 87: Reviewed & Approved by: Name Date Signature R&D Director /VP - - - VP of QA & RA/ QA Manager R&D - - -\n",
      "Duplicate text found in row 88: SOP 3-01-21 4  Appendix Appendix status - released Revision  7 Valid from ‏20/04/2017 Product/s name Disposable Pressure Transducer Document status Under Edit Author - Title Revision C Risk Management Plan Release Date - Document# Doc-081938 Page 7 of 7\n",
      "Duplicate text found in row 89: Company: Elcam Medical\n",
      "Duplicate text found in row 90: Product Description:\n",
      "Duplicate text found in row 91: The DPT (Disposable Pressure Transducer) is a product used for arterial blood pressure sensing. There are two versions DIPT (Integrated DPT) and DPT (also called DSPT -Straight DPT).\n",
      "Duplicate text found in row 92: This Risk management plan covers all risk management activities required for the design change projects of the high pressure stopcocks.\n",
      "Duplicate text found in row 93: Projects lifecycles are usually divided to:\n",
      "Duplicate text found in row 94: project initiation\n",
      "Duplicate text found in row 95: Design Planning\n",
      "Duplicate text found in row 96: Design Input\n",
      "Duplicate text found in row 97: Design Output\n",
      "Duplicate text found in row 98: Design Verification & Validation (V&V)\n",
      "Duplicate text found in row 99: Process Validation\n",
      "Duplicate text found in row 100: Transfer to production\n",
      "Duplicate text found in row 101: Production and post marketing\n",
      "Duplicate text found in row 102: First Risk review meeting is to be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project.\n",
      "Duplicate text found in row 103: Purpose:\n",
      "Duplicate text found in row 104: The purpose of this document is planning the risk management process for the Disposable Pressure Transducer family of products.\n",
      "Duplicate text found in row 105: Definitions:\n",
      "Duplicate text found in row 106: FMEA: Failure Mode and Effect Analysis.\n",
      "Duplicate text found in row 107: Harm: physical injury or damage to the health of people, or damage to property or the environment.\n",
      "Duplicate text found in row 108: Hazard: potential source of harm. \n",
      "Duplicate text found in row 109: Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).\n",
      "Duplicate text found in row 110: Risk: combination of the probability of occurrence of harm and the severity of that harm.\n",
      "Duplicate text found in row 111: RPN: Risk Priority number, Multiply of Severity*Probability*Detectability.\n",
      "Duplicate text found in row 112: ALARP:  As Low As Reasonably Possible.\n",
      "Duplicate text found in row 113: AFAP:  As Far as Possible.\n",
      "Duplicate text found in row 114: Method:\n",
      "Duplicate text found in row 115: 4.1. Risk Management Process description:\n",
      "Duplicate text found in row 116: Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam's SOP# 03-01-21.\n",
      "Duplicate text found in row 117: The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.\n",
      "Duplicate text found in row 118: (The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. \n",
      "Duplicate text found in row 119: The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\n",
      "Duplicate text found in row 120: 4.1.1. Risk Analysis:\n",
      "Duplicate text found in row 121: First step is listing the intended use or purpose of the product and its characteristics related to its safety. \n",
      "Duplicate text found in row 122: Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. \n",
      "Duplicate text found in row 123: 4.1.2. Risk Evaluation:\n",
      "Duplicate text found in row 124: The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. \n",
      "Duplicate text found in row 125: Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: \n",
      "Duplicate text found in row 126: Probability of occurrence (P):  \n",
      "Duplicate text found in row 127: Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:10,000 - 1:1,000,000 Low probability, rare occurrence 4 1:1,000 - 1:10,000 Will occur several times 6 1:100 - 1:1,000 Will occur several times, often 8 More than 1:100 High probability, likely to occur frequently\n",
      "Duplicate text found in row 128: Degree of Severity (S): \n",
      "Duplicate text found in row 129: S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.\n",
      "Duplicate text found in row 130: Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.\n",
      "Duplicate text found in row 131: Degree of Detectability (D) – Relevant mainly to Process risks: \n",
      "Duplicate text found in row 132: D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.\n",
      "Duplicate text found in row 133: RPN calculation:\n",
      "Duplicate text found in row 134: The calculation of the Risk Priority Number (RPN) is done by multiplying the risk values:         (S x P) or (S x P x D).\n",
      "Duplicate text found in row 135: According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). \n",
      "Duplicate text found in row 136: Risk Priority Levels:\n",
      "Duplicate text found in row 137: (S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P) ≤32 (Yellow) Medium (ALARP/AFAP*) 32< (S*P) (Red) High\n",
      "Duplicate text found in row 138: Or\n",
      "Duplicate text found in row 139: (S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High\n",
      "Duplicate text found in row 140: Green area – Low rated risks.\n",
      "Duplicate text found in row 141: Yellow area – Medium rated risks. \n",
      "Duplicate text found in row 142: Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.\n",
      "Duplicate text found in row 143: Red area – High rated risk, additional actions should be taken to reduce this risk. \n",
      "Duplicate text found in row 144: 4.1.3. Risk Control:\n",
      "Duplicate text found in row 145: For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.\n",
      "Duplicate text found in row 146: The risk control measures should be one or more of the following options in the priority order listed:\n",
      "Duplicate text found in row 147: Inherent safety by design\n",
      "Duplicate text found in row 148: Protective measures in the product itself or in the manufacturing process.\n",
      "Duplicate text found in row 149: Information for safety\n",
      "Duplicate text found in row 150: Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.\n",
      "Duplicate text found in row 151: At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. \n",
      "Duplicate text found in row 152: 4.1.4. Production & Post-production Information:\n",
      "Duplicate text found in row 153: After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\n",
      "Duplicate text found in row 154: 4.2. Verification plan\n",
      "Duplicate text found in row 155: After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).\n",
      "Duplicate text found in row 156: The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).\n",
      "Duplicate text found in row 157: Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.\n",
      "Duplicate text found in row 158: Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.\n",
      "Duplicate text found in row 159: Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.\n",
      "Duplicate text found in row 160: 4.3. Allocation of responsibilities:\n",
      "Duplicate text found in row 161: 4.3.1. Responsibility for assuring that the risk management activities are done is by the Project Manager.\n",
      "Duplicate text found in row 162: 4.3.2. Person In charge for Risk Management activities execution: Quality Engineer in R&D.\n",
      "Duplicate text found in row 163: 4.3.3. Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.\n",
      "Duplicate text found in row 164: 4.3.4. Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.\n",
      "Duplicate text found in row 165: 4.3.5. Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.\n",
      "Duplicate text found in row 166: Documenting Risk Management Process\n",
      "Duplicate text found in row 167: The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 or 8 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\n",
      "Duplicate text found in row 168: General Risk management documents (for family of products) related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system and using appendix 7 of SOP 3-01-21. \n",
      "Duplicate text found in row 169: Summary\n",
      "Duplicate text found in row 170: This document outlines the risk management activities for the Disposable Pressure Transducer family of products. It determines the scales of rating them and the Risk Priority Levels. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.\n",
      "Duplicate text found in row 171: Document Revision Control:\n",
      "Duplicate text found in row 172: Revision History Tracking: Date: Revision 0- first release 19-Nov-2008 Revision A - Overall review and updates 30-Dec-2014 Revision B - Updating document format. Adding definitions of ALARP and AFAP to section 3. Updating Risk evaluation definitions in section 4.1.2.according to the new version of annexes 5, 7 and 8 of SOP 3-01-21. Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks) and Updating location of general risk documents (in the EPDM system). 12-Jan-2017 Revision C - Correcting Probability scales and Risk Priority Levels according latest version of Appendix 5, 7 and 8 of SOP 3-01-21. Adding guidance for using appendix 5, 7 and 8 of SOP 3-01-21 to \"Documenting Risk Management Process\" section. 16-Aug-2017\n",
      "Duplicate text found in row 173: Review and approval:\n",
      "Duplicate text found in row 174: Written by: Name Date Signature QA Eng. - - -\n",
      "Duplicate text found in row 175: Reviewed & Approved by: Name Date Signature Chief Technology Officer /R&D Manager - - - Chief Quality & RA Officer/ QA Manager R&D - - -\n",
      "Duplicate text found in row 176: 3-01-21  SOP 4  Appendix Appendix status - released Revision  5 Valid from ‏25/12/2016 Product/s name - Document status Under Edit Author - Title Revision B Risk Management Plan Release Date - Document# Doc-076035 Page 7 of 7\n",
      "Duplicate text found in row 177: Company: Elcam Medical\n",
      "Duplicate text found in row 178: Product Description:\n",
      "Duplicate text found in row 179: The DPT (Disposable Pressure Transducer) is a product used for arterial blood pressure sensing. There are two versions DIPT (Integrated DPT) and DPT (also called DSPT -Straight DPT).\n",
      "Duplicate text found in row 180: This Risk management plan covers all risk management activities required for the design change projects of the high pressure stopcocks.\n",
      "Duplicate text found in row 181: Projects lifecycles are usually divided to:\n",
      "Duplicate text found in row 182: project initiation\n",
      "Duplicate text found in row 183: Design Planning\n",
      "Duplicate text found in row 184: Design Input\n",
      "Duplicate text found in row 185: Design Output\n",
      "Duplicate text found in row 186: Design Verification & Validation (V&V)\n",
      "Duplicate text found in row 187: Process Validation\n",
      "Duplicate text found in row 188: Transfer to production\n",
      "Duplicate text found in row 189: Production and post marketing\n",
      "Duplicate text found in row 190: First Risk review meeting is to be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project.\n",
      "Duplicate text found in row 191: Purpose:\n",
      "Duplicate text found in row 192: The purpose of this document is planning the risk management process for the Disposable Pressure Transducer modifications.\n",
      "Duplicate text found in row 193: Definitions:\n",
      "Duplicate text found in row 194: FMEA: Failure Mode and Effect Analysis.\n",
      "Duplicate text found in row 195: Harm: physical injury or damage to the health of people, or damage to property or the environment.\n",
      "Duplicate text found in row 196: Hazard: potential source of harm. \n",
      "Duplicate text found in row 197: Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).\n",
      "Duplicate text found in row 198: Risk: combination of the probability of occurrence of harm and the severity of that harm.\n",
      "Duplicate text found in row 199: RPN: Risk Priority number, Multiply of Severity*Probability*Detectability.\n",
      "Duplicate text found in row 200: ALARP:  As Low As Reasonably Possible.\n",
      "Duplicate text found in row 201: AFAP:  As Far as Possible.\n",
      "Duplicate text found in row 202: Method:\n",
      "Duplicate text found in row 203: Risk Management Process description:\n",
      "Duplicate text found in row 204: Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam's SOP# 03-01-21.\n",
      "Duplicate text found in row 205: Method description \n",
      "Duplicate text found in row 206: The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.\n",
      "Duplicate text found in row 207: The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. \n",
      "Duplicate text found in row 208: The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\n",
      "Duplicate text found in row 209: Risk Analysis:\n",
      "Duplicate text found in row 210: First step is listing the intended use or purpose of the product and its characteristics related to its safety. \n",
      "Duplicate text found in row 211: Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. \n",
      "Duplicate text found in row 212: Risk Evaluation:\n",
      "Duplicate text found in row 213: The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. \n",
      "Duplicate text found in row 214: Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: \n",
      "Duplicate text found in row 215: Probability of occurrence (P):  \n",
      "Duplicate text found in row 216: Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:100,000 - 1:1,000,000 Low probability, rare occurrence 4 1:100,000 - 1:10,000 Will occur several times 6 1:100 - 1:10,000 Will occur several times 8 More than 1:100 High probability, likely to occur frequently\n",
      "Duplicate text found in row 217: Degree of Severity (S): \n",
      "Duplicate text found in row 218: S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.\n",
      "Duplicate text found in row 219: Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.\n",
      "Duplicate text found in row 220: Degree of Detectability (D) – Relevant mainly to Process risks: \n",
      "Duplicate text found in row 221: D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.\n",
      "Duplicate text found in row 222: RPN calculation:\n",
      "Duplicate text found in row 223: The calculation of the Risk Priority Number (RPN) is done by multiplying the risk values:         (S x P) or (S x P x D).\n",
      "Duplicate text found in row 224: According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). \n",
      "Duplicate text found in row 225: Risk Priority Levels:\n",
      "Duplicate text found in row 226: (S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P)<32 (Yellow) Medium (ALARP/AFAP*) 32≤(S*P) (Red) High\n",
      "Duplicate text found in row 227: Or\n",
      "Duplicate text found in row 228: (S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High\n",
      "Duplicate text found in row 229: Green area – Low rated risks.\n",
      "Duplicate text found in row 230: Yellow area – Medium rated risks. \n",
      "Duplicate text found in row 231: Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.\n",
      "Duplicate text found in row 232: Red area – High rated risk, additional actions should be taken to reduce this risk. \n",
      "Duplicate text found in row 233: Risk Control:\n",
      "Duplicate text found in row 234: For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.\n",
      "Duplicate text found in row 235: The risk control measures should be one or more of the following options in the priority order listed:\n",
      "Duplicate text found in row 236: Inherent safety by design\n",
      "Duplicate text found in row 237: Protective measures in the product itself or in the manufacturing process.\n",
      "Duplicate text found in row 238: Information for safety\n",
      "Duplicate text found in row 239: Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.\n",
      "Duplicate text found in row 240: At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. \n",
      "Duplicate text found in row 241: Production & Post-production Information:\n",
      "Duplicate text found in row 242: After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\n",
      "Duplicate text found in row 243: Verification plan\n",
      "Duplicate text found in row 244: After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).\n",
      "Duplicate text found in row 245: The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).\n",
      "Duplicate text found in row 246: Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.\n",
      "Duplicate text found in row 247: Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.\n",
      "Duplicate text found in row 248: Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.\n",
      "Duplicate text found in row 249: Allocation of responsibilities:\n",
      "Duplicate text found in row 250: Responsibility for assuring that the risk management activities are done is by the Project Manager.\n",
      "Duplicate text found in row 251: Person In charge for Risk Management activities execution: Quality Engineer in R&D.\n",
      "Duplicate text found in row 252: Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.\n",
      "Duplicate text found in row 253: Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.\n",
      "Duplicate text found in row 254: Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.\n",
      "Duplicate text found in row 255: Documenting Risk Management Process\n",
      "Duplicate text found in row 256: The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\n",
      "Duplicate text found in row 257: Risk general management documents related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system.\n",
      "Duplicate text found in row 258: Summary\n",
      "Duplicate text found in row 259: This document outlines the risk management activities for all DPT modification projects. It determines the scales of rating them and the acceptance criteria. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.\n",
      "Duplicate text found in row 260: Document Revision Control:\n",
      "Duplicate text found in row 261: Revision History Tracking: Date: Revision 0- first release 19-Nov-2008 Revision A - Overall review and updates 30-Dec-2014 Revision B - Updating document format. Adding definitions of ALARP and AFAP to section 3. Updating Risk evaluation definitions in section 4.1.2.according to the new version of annexes 5, 7 and 8 of SOP 3-01-21. Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks) and Updating location of general risk documents (in the EPDM system). 12-Jan-2017\n",
      "Duplicate text found in row 262: Review and approval:\n",
      "Duplicate text found in row 263: Written by: Name Date Signature QA Eng. - - -\n",
      "Duplicate text found in row 264: Reviewed & Approved by: Name Date Signature R&D Director /VP - - - VP of QA & RA/ QA Manager R&D - - -\n",
      "Duplicate text found in row 265: 3-01-21  SOP 4  Appendix Appendix status - released Revision  5 Valid from ‏25/12/2016 Product/s name Closed Stopcock & MRVLS Document status Under Edit Author - Title Revision B Risk Management Plan Release Date - Document# Doc-075342 Page 9 of 9\n",
      "Duplicate text found in row 266: Company: Elcam Medical\n",
      "Duplicate text found in row 267: Product Description:\n",
      "Duplicate text found in row 268: Elcam Closed Swabable Stopcocks (CSTP) and Minimal Residual Volume Luer-activated Swabable-stopcock (MRVLS) stopcocks are indicated for fluid flow directional control and for providing access port(s) for administration of solutions. Typical uses include pressure monitoring, intravenous fluid administration and transfusion.\n",
      "Duplicate text found in row 269: The Closed Swabable Stopcock includes an addition of a component that\n",
      "Duplicate text found in row 270: functions as a closed luer-activated valve.\n",
      "Duplicate text found in row 271: The MRVLS feature, is an additional option that can be added to the Closed Swabable\n",
      "Duplicate text found in row 272: Stopcock and provides a stopcock with a minimal residual volume.\n",
      "Duplicate text found in row 273: This Risk management plan covers all risk management activities required for CSTP and MRVLS projects as well as their design change projects.\n",
      "Duplicate text found in row 274: Their lifecycle stages are divided to:\n",
      "Duplicate text found in row 275: project initiation\n",
      "Duplicate text found in row 276: Design Planning\n",
      "Duplicate text found in row 277: Design Input\n",
      "Duplicate text found in row 278: Design Output\n",
      "Duplicate text found in row 279: Design Verification & Validation\n",
      "Duplicate text found in row 280: Process Validation\n",
      "Duplicate text found in row 281: Transfer to production\n",
      "Duplicate text found in row 282: Production & Post marketing\n",
      "Duplicate text found in row 283: First Risk review meeting shall be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project\n",
      "Duplicate text found in row 284: Purpose:\n",
      "Duplicate text found in row 285: The purpose of this document is planning the risk management process for the Closed Stopcock and MRVLS family of products.\n",
      "Duplicate text found in row 286: Definitions:\n",
      "Duplicate text found in row 287: FMEA: Failure Mode and Effect Analysis.\n",
      "Duplicate text found in row 288: Harm: physical injury or damage to the health of people, or damage to property or the environment.\n",
      "Duplicate text found in row 289: Hazard: potential source of harm. \n",
      "Duplicate text found in row 290: Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).\n",
      "Duplicate text found in row 291: Risk: combination of the probability of occurrence of harm and the severity of that harm.\n",
      "Duplicate text found in row 292: RPN: Risk Priority number, Multiply of Severity*Probability*Detectability.\n",
      "Duplicate text found in row 293: ALARP:  As Low As Reasonably Possible.\n",
      "Duplicate text found in row 294: AFAP:  As Far as Possible.\n",
      "Duplicate text found in row 295: Method:\n",
      "Duplicate text found in row 296: 4.1. Risk Management Process description:\n",
      "Duplicate text found in row 297: Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam's SOP# 03-01-21.\n",
      "Duplicate text found in row 298: The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.\n",
      "Duplicate text found in row 299: (The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. \n",
      "Duplicate text found in row 300: The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\n",
      "Duplicate text found in row 301: 4.1.1. Risk Analysis:\n",
      "Duplicate text found in row 302: First step is listing the intended use or purpose of the product and its characteristics related to its safety. \n",
      "Duplicate text found in row 303: Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. \n",
      "Duplicate text found in row 304: 4.1.2. Risk Evaluation:\n",
      "Duplicate text found in row 305: The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. \n",
      "Duplicate text found in row 306: Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: \n",
      "Duplicate text found in row 307: Probability of occurrence (P):  \n",
      "Duplicate text found in row 308: Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:100,000 - 1:1,000,000 Low probability, rare occurrence 4 1:100,000 - 1:10,000 Will occur several times 6 1:100 - 1:10,000 Will occur several times 8 More than 1:100 High probability, likely to occur frequently\n",
      "Duplicate text found in row 309: Degree of Severity (S): \n",
      "Duplicate text found in row 310: S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.\n",
      "Duplicate text found in row 311: Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.\n",
      "Duplicate text found in row 312: Degree of Detectability (D): \n",
      "Duplicate text found in row 313: D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.\n",
      "Duplicate text found in row 314: RPN calculation:\n",
      "Duplicate text found in row 315: The calculation of the Risk Priority Number (RPN) is done by multiplying the risk analysis values:            (S x P) or (S x P x D).\n",
      "Duplicate text found in row 316: According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). \n",
      "Duplicate text found in row 317: Risk Priority Levels:\n",
      "Duplicate text found in row 318: (S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P)<32 (Yellow) Medium (ALARP/AFAP*) 32≤(S*P) (Red) High\n",
      "Duplicate text found in row 319: Or\n",
      "Duplicate text found in row 320: (S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High\n",
      "Duplicate text found in row 321: Green area – Low rated risks.\n",
      "Duplicate text found in row 322: Yellow area – Medium rated risks. \n",
      "Duplicate text found in row 323: Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.\n",
      "Duplicate text found in row 324: Red area – High rated risk, additional actions should be taken to reduce this risk. \n",
      "Duplicate text found in row 325: 4.1.3. Risk Control:\n",
      "Duplicate text found in row 326: For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.\n",
      "Duplicate text found in row 327: The risk control measures should be one or more of the following options in the priority order listed:\n",
      "Duplicate text found in row 328: Inherent safety by design\n",
      "Duplicate text found in row 329: Protective measures in the product itself or in the manufacturing process.\n",
      "Duplicate text found in row 330: Information for safety\n",
      "Duplicate text found in row 331: Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.\n",
      "Duplicate text found in row 332: At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. \n",
      "Duplicate text found in row 333: 4.1.4. Production & Post-production Information:\n",
      "Duplicate text found in row 334: After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\n",
      "Duplicate text found in row 335: 4.2. Verification plan\n",
      "Duplicate text found in row 336: After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).\n",
      "Duplicate text found in row 337: The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).\n",
      "Duplicate text found in row 338: Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.\n",
      "Duplicate text found in row 339: Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.\n",
      "Duplicate text found in row 340: Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.\n",
      "Duplicate text found in row 341: 4.3. Allocation of responsibilities:\n",
      "Duplicate text found in row 342: 4.3.1. Responsibility for assuring that the risk management activities are done is by the Project Manager.\n",
      "Duplicate text found in row 343: 4.3.2. Person In charge for Risk Management activities execution: Quality Engineer in R&D.\n",
      "Duplicate text found in row 344: 4.3.3. Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.\n",
      "Duplicate text found in row 345: 4.3.4. Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.\n",
      "Duplicate text found in row 346: 4.3.5. Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.\n",
      "Duplicate text found in row 347: Documenting Risk Management Process\n",
      "Duplicate text found in row 348: The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\n",
      "Duplicate text found in row 349: Risk general management documents related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system.\n",
      "Duplicate text found in row 350: Summary\n",
      "Duplicate text found in row 351: This document outlines the risk management activities for CSTP and MRVLS family of products. It determines the scales of rating them and the acceptance criteria. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.\n",
      "Duplicate text found in row 352: Document Revision Control:\n",
      "Duplicate text found in row 353: Revision History Tracking: Date: Revision 0- first version 5-July-2012 Revision A – update of referenced standards and definition of ALARP/AFAP. 16-Mar-2014 Revision B – Updating document format; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 \"Responsibilities\" and 4.3. \"Allocation of responsibilities\". 27-Dec-2016\n",
      "Duplicate text found in row 354: Review and approval:\n",
      "Duplicate text found in row 355: Written by: Name Date Signature QA Eng. - - -\n",
      "Duplicate text found in row 356: Reviewed & Approved by: Name Date Signature R&D Director /VP - - - VP of QA & RA/ QA Manager R&D - - -\n",
      "Duplicate text found in row 357: SOP 3-01-21 4  Appendix Appendix status - released Revision  7 Valid from ‏20/04/2017 Product/s name Closed Stopcock & MRVLS Document status Under Edit Author - Title Revision C Risk Management Plan Release Date - Document# Doc-081935 Page 8 of 8\n",
      "Duplicate text found in row 358: Company: Elcam Medical\n",
      "Duplicate text found in row 359: Product Description:\n",
      "Duplicate text found in row 360: Elcam Closed Swabable Stopcocks (CSTP) and Minimal Residual Volume Luer-activated Swabable-stopcock (MRVLS) stopcocks are indicated for fluid flow directional control and for providing access port(s) for administration of solutions. Typical uses include pressure monitoring, intravenous fluid administration and transfusion.\n",
      "Duplicate text found in row 361: The Closed Swabable Stopcock includes an addition of a component that\n",
      "Duplicate text found in row 362: functions as a closed luer-activated valve.\n",
      "Duplicate text found in row 363: The MRVLS feature, is an additional option that can be added to the Closed Swabable\n",
      "Duplicate text found in row 364: Stopcock and provides a stopcock with a minimal residual volume.\n",
      "Duplicate text found in row 365: This Risk management plan covers all risk management activities required for CSTP and MRVLS projects as well as their design change projects.\n",
      "Duplicate text found in row 366: Their lifecycle stages are divided to:\n",
      "Duplicate text found in row 367: project initiation\n",
      "Duplicate text found in row 368: Design Planning\n",
      "Duplicate text found in row 369: Design Input\n",
      "Duplicate text found in row 370: Design Output\n",
      "Duplicate text found in row 371: Design Verification & Validation\n",
      "Duplicate text found in row 372: Process Validation\n",
      "Duplicate text found in row 373: Transfer to production\n",
      "Duplicate text found in row 374: Production & Post marketing\n",
      "Duplicate text found in row 375: First Risk review meeting shall be performed after Design Input and before Design V&V. Risk Management activities are categorized as Design Review Activities along the project\n",
      "Duplicate text found in row 376: Purpose:\n",
      "Duplicate text found in row 377: The purpose of this document is planning the risk management process for the Closed Stopcock and MRVLS family of products.\n",
      "Duplicate text found in row 378: Definitions:\n",
      "Duplicate text found in row 379: FMEA: Failure Mode and Effect Analysis.\n",
      "Duplicate text found in row 380: Harm: physical injury or damage to the health of people, or damage to property or the environment.\n",
      "Duplicate text found in row 381: Hazard: potential source of harm. \n",
      "Duplicate text found in row 382: Hazardous situation: circumstances in which people, property, or the environment are exposed to one or more hazard(s).\n",
      "Duplicate text found in row 383: Risk: combination of the probability of occurrence of harm and the severity of that harm.\n",
      "Duplicate text found in row 384: RPN: Risk Priority number, Multiply of Severity*Probability*Detectability.\n",
      "Duplicate text found in row 385: ALARP:  As Low As Reasonably Possible.\n",
      "Duplicate text found in row 386: AFAP:  As Far as Possible.\n",
      "Duplicate text found in row 387: Method:\n",
      "Duplicate text found in row 388: 4.1. Risk Management Process description:\n",
      "Duplicate text found in row 389: Risk Management process will be performed as required by ISO 14971:2007 and BS EN ISO 14971:2012, (\"Medical Devices – Application of risk management to medical devices\") and in accordance with Elcam's SOP# 03-01-21.\n",
      "Duplicate text found in row 390: The process will include Risk Analysis, Risk Evaluation and Risk Control and at the end of the process also Production & Post Production information.\n",
      "Duplicate text found in row 391: (The method for risk analysis and evaluation to be used is mainly FMEA (Fail Mode & Effect Analysis). Other techniques will be used as well when needed. \n",
      "Duplicate text found in row 392: The emphasis will be on risks primarily to the patient, but also to the operator, other persons, other equipment and the environment occurs during the product shelf life and/or in-use life. Risks which effect Elcam's image or Elcam's manufacturing facilities that do not affect product's safety or performance are not included within this Risk Management Process.\n",
      "Duplicate text found in row 393: 4.1.1. Risk Analysis:\n",
      "Duplicate text found in row 394: First step is listing the intended use or purpose of the product and its characteristics related to its safety. \n",
      "Duplicate text found in row 395: Then, identifying the known or foreseeable hazards and hazardous situations in normal and fault conditions, their causes and estimating the risks for each hazardous situation. This identification will initially be performed by a review meeting after design Input phase, after establishing the Device Requirements and the Product Specifications. \n",
      "Duplicate text found in row 396: 4.1.2. Risk Evaluation:\n",
      "Duplicate text found in row 397: The identified hazardous situations are evaluated for their risk probability of occurrence (P), severity (S) and detectability (D) according to the scales described below. Afterwards the RPN number is calculated by multiplying the ratings for each hazard and the acceptability is determined according to the acceptance criteria. \n",
      "Duplicate text found in row 398: Each parameter (P, S, or D) will be analyzed in order to rank and estimate the risk: \n",
      "Duplicate text found in row 399: Probability of occurrence (P):  \n",
      "Duplicate text found in row 400: Value Probability for occurrence Verbal description for probability 1 Less than 1 in 1,000,000 Evidence that will not occur 2 1:10,000 - 1:1,000,000 Low probability, rare occurrence 4 1:1,000 - 1:10,000 Will occur several times 6 1:100 - 1:1,000 Will occur several times, often 8 More than 1:100 High probability, likely to occur frequently\n",
      "Duplicate text found in row 401: Degree of Severity (S): \n",
      "Duplicate text found in row 402: S Rating Severity Severity to Patient/User Severity to Elcam Severity to Manufacture 1 Minor All is fine up to small discomfort, minor damage in performance. All is fine up to deviations in spec border. Small effect on equipment or product, a few production hours loss. 2 Medium Degradation in performance without harm. Damage to image, do not meet spec. Degradation in equipment or its operation small effect on product in non-functional characters, a few days loss. 4 Severe The part does not function but does not cause harm. Need to replace parts, severe impact to image, will not meet fundamental characteristic in spec. Medium degradation in equipment or its operation affecting product in non-functional characters, two-three weeks loss. 6 Severe - critical The product does not function and causes injury or condition requiring medical treatment. Severe impact to image, product will not meet the requirements of spec, market loss. High deterioration in equipment or its operation severely affecting production or product functionality, several week losses. 8 Critical Severe harm to patient: death, irreversible injury or condition or long term medical aid. Low suit, market loss. Severe damage to equipment, not being able to produce at all or producing non-functional products, loss of more than month and a half.\n",
      "Duplicate text found in row 403: Rate according to severity to patient/user or their environment. If the risk has an effect on several fields (patient/user and/or Elcam and/or Manufacture) rate according to the worst of all.\n",
      "Duplicate text found in row 404: Degree of Detectability (D) – Relevant mainly to Process risks: \n",
      "Duplicate text found in row 405: D Rating Defect Detection 1 Defect, if occurred, will always be detected at Elcam during production. 2 Defect, if occurred, will occasionally be detected at Elcam during production. 3 Defects, if occurred, will rarely be detected at Elcam or Will be detected by customer (not end user). 4 Defects, if occurred, will not be detected at Elcam. It will always be detected by the end user.\n",
      "Duplicate text found in row 406: RPN calculation:\n",
      "Duplicate text found in row 407: The calculation of the Risk Priority Number (RPN) is done by multiplying the risk values:         (S x P) or (S x P x D).\n",
      "Duplicate text found in row 408: According to the calculated RPN value the priority for mitigation is determined (Risk Priority Level). \n",
      "Duplicate text found in row 409: Risk Priority Levels:\n",
      "Duplicate text found in row 410: (S*P) value Color Risk priority Level (S*P)≤8 (Green) Low 8<(S*P) ≤32 (Yellow) Medium (ALARP/AFAP*) 32< (S*P) (Red) High\n",
      "Duplicate text found in row 411: Or\n",
      "Duplicate text found in row 412: (S*P*D) value Color Risk Priority Level (S*P*D)≤8 (Green) Low 8<(S*P*D)≤32 (Yellow) Medium (ALARP/AFAP*) 32<(S*P*D) (Red) High\n",
      "Duplicate text found in row 413: Green area – Low rated risks.\n",
      "Duplicate text found in row 414: Yellow area – Medium rated risks. \n",
      "Duplicate text found in row 415: Risks in the ALARP/AFAP area (ALARP is according to definition of ISO 14971:2007 AFAP is according to definition in BS EN ISO 14971:2012). Acceptable but require additional controls and monitoring. There should be actions to reduce them further and they require periodical review.\n",
      "Duplicate text found in row 416: Red area – High rated risk, additional actions should be taken to reduce this risk. \n",
      "Duplicate text found in row 417: 4.1.3. Risk Control:\n",
      "Duplicate text found in row 418: For each risk, whether marked in green, yellow or red, Risk Control measures should be taken in order to reduce the severity of the harm or reduce the probability of its occurrence.\n",
      "Duplicate text found in row 419: The risk control measures should be one or more of the following options in the priority order listed:\n",
      "Duplicate text found in row 420: Inherent safety by design\n",
      "Duplicate text found in row 421: Protective measures in the product itself or in the manufacturing process.\n",
      "Duplicate text found in row 422: Information for safety\n",
      "Duplicate text found in row 423: Risk Control includes defining the measures to be taken in order to reduce the risks, Implementation of the risk control measures and verification of their implementation and their effectiveness, Residual Risk Evaluation after the Implementation. If measures are not practical Risk to Benefit Analysis should be made in order to demonstrate whether the products` benefits outweigh the residual risk. Risks arising from the risk control measures should be identified as well.\n",
      "Duplicate text found in row 424: At the end of the risk control measures, the Acceptability of the Overall Residual Risk is to be documented. \n",
      "Duplicate text found in row 425: 4.1.4. Production & Post-production Information:\n",
      "Duplicate text found in row 426: After the end of the development phase, for each family of products, the risks should be reviewed according to information gained from the production of the device and afterwards information after the device is being sent to customers (customers' feedback and satisfaction, complaints, information from users, operators etc.). This information shall be evaluated to identify any unrecognized hazards and hazardous situations and to evaluate acceptability of risks that were identified previously.\n",
      "Duplicate text found in row 427: 4.2. Verification plan\n",
      "Duplicate text found in row 428: After each important phase during product lifecycle a risk review meeting is to be performed (Initial risk review meeting: after Design Input).\n",
      "Duplicate text found in row 429: The Risk Analysis, Evaluation and Control activities are to be initially identified by a review meeting attending represents of all relevant departments (R&D, Manufacturing Eng, QA, Marketing, production etc. including someone not directly involved in the project or product).\n",
      "Duplicate text found in row 430: Reviews in order to verify that mitigation activities were performed and assessment of their effectiveness are to be performed by the person in charge of risk management from QA and the project manager.\n",
      "Duplicate text found in row 431: Overall residual risks acceptability and Risk to benefit analysis is also to be performed by QA and project manager.\n",
      "Duplicate text found in row 432: Other risk reviews in order to view the pre-identified hazards, risks, their evaluations and their relevance and to identify new hazards will be performed in a risk review meeting with representatives of all relevant departments.\n",
      "Duplicate text found in row 433: 4.3. Allocation of responsibilities:\n",
      "Duplicate text found in row 434: 4.3.1. Responsibility for assuring that the risk management activities are done is by the Project Manager.\n",
      "Duplicate text found in row 435: 4.3.2. Person In charge for Risk Management activities execution: Quality Engineer in R&D.\n",
      "Duplicate text found in row 436: 4.3.3. Responsibility of assuring that Risk Control activities are done as indicated in the Risk Management File is by the project manager.\n",
      "Duplicate text found in row 437: 4.3.4. Risk Control measures are to be performed as indicated in the Risk Management File by the people mentioned there.\n",
      "Duplicate text found in row 438: 4.3.5. Responsibility for Production & Post Production Information gathering & analyzing is Quality Engineer in R&D.\n",
      "Duplicate text found in row 439: Documenting Risk Management Process\n",
      "Duplicate text found in row 440: The Risk Management Process will be documented in the product's Design History File (DHF).  It will be according to the format specified in Appendix 5 or 8 of SOP#3-01-21. The risk management file will be managed as a controlled document, revised with the progression of the risk management process and all its revisions will be kept for process tracking in the design history file.\n",
      "Duplicate text found in row 441: General Risk management documents (for family of products) related to production and post production stages will be documented separately afterwards in \"Risk Management\" folder at the EPDM system and using appendix 7 of SOP 3-01-21. \n",
      "Duplicate text found in row 442: Summary\n",
      "Duplicate text found in row 443: This document outlines the risk management activities for the CSTP and MRVLS family of products. It determines the scales of rating them and the Risk Priority Levels. It also determines the means of reviewing and verifying them and the responsibilities. The product lifecycle stages in which this plan is applicable are as described in the scope.\n",
      "Duplicate text found in row 444: Document Revision Control:\n",
      "Duplicate text found in row 445: Revision History Tracking: Date: Revision 0- first version 5-July-2012 Revision A – update of referenced standards and definition of ALARP/AFAP. 16-Mar-2014 Revision B – Updating document format; Moving the definitions of ALARP and AFAP to section 3; Updating Risk evaluation definitions in section 4.1.2. according to the new version of annexes 5, 7 and 8 of SOP 3-01-21.; Adding guidance on severity rating; Adding clarification regarding the risk control (should be performed for all risks); Updating location of general risk documents (in the EPDM system); and Correcting duplicate of sections 4.3 \"Responsibilities\" and 4.3. \"Allocation of responsibilities\". 27-Dec-2016 Revision C – Correcting Probability scales and Risk Priority Levels according latest version of Appendix 5, 7 and 8 of SOP 3-01-21. Adding guidance for using appendix 5, 7 and 8 of SOP 3-01-21 to \"Documenting Risk Management Process\" section. 17-May-2017\n",
      "Duplicate text found in row 446: Review and approval:\n",
      "Duplicate text found in row 447: Written by: Name Date Signature QA Eng. - - -\n",
      "Duplicate text found in row 448: Reviewed & Approved by: Name Date Signature Chief Technology Officer /R&D Manager - - - Chief Quality & RA Officer/ QA Manager R&D - - -\n"
     ]
    }
   ],
   "source": [
    "#iterate over the rows of the DataFrame and check if there is any duplicate text\n",
    "for index, row in df.iterrows():\n",
    "    if df['text'].duplicated().any():\n",
    "        print(f\"Duplicate text found in row {index}: {row['text']}\")\n",
    "    else:\n",
    "        print(f\"No duplicate text found in row {index}: {row['text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package unstructured_client.models.operations in unstructured_client.models:\n",
      "\n",
      "NAME\n",
      "    unstructured_client.models.operations - Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    cancel_job\n",
      "    create_destination\n",
      "    create_source\n",
      "    create_workflow\n",
      "    delete_destination\n",
      "    delete_source\n",
      "    delete_workflow\n",
      "    get_destination\n",
      "    get_job\n",
      "    get_source\n",
      "    get_workflow\n",
      "    list_destinations\n",
      "    list_jobs\n",
      "    list_sources\n",
      "    list_workflows\n",
      "    partition\n",
      "    run_workflow\n",
      "    update_destination\n",
      "    update_source\n",
      "    update_workflow\n",
      "\n",
      "CLASSES\n",
      "    builtins.dict(builtins.object)\n",
      "        unstructured_client.models.operations.cancel_job.CancelJobRequestTypedDict\n",
      "        unstructured_client.models.operations.cancel_job.CancelJobResponseTypedDict\n",
      "        unstructured_client.models.operations.create_destination.CreateDestinationRequestTypedDict\n",
      "        unstructured_client.models.operations.create_destination.CreateDestinationResponseTypedDict\n",
      "        unstructured_client.models.operations.create_source.CreateSourceRequestTypedDict\n",
      "        unstructured_client.models.operations.create_source.CreateSourceResponseTypedDict\n",
      "        unstructured_client.models.operations.create_workflow.CreateWorkflowRequestTypedDict\n",
      "        unstructured_client.models.operations.create_workflow.CreateWorkflowResponseTypedDict\n",
      "        unstructured_client.models.operations.delete_destination.DeleteDestinationRequestTypedDict\n",
      "        unstructured_client.models.operations.delete_destination.DeleteDestinationResponseTypedDict\n",
      "        unstructured_client.models.operations.delete_source.DeleteSourceRequestTypedDict\n",
      "        unstructured_client.models.operations.delete_source.DeleteSourceResponseTypedDict\n",
      "        unstructured_client.models.operations.delete_workflow.DeleteWorkflowRequestTypedDict\n",
      "        unstructured_client.models.operations.delete_workflow.DeleteWorkflowResponseTypedDict\n",
      "        unstructured_client.models.operations.get_destination.GetDestinationRequestTypedDict\n",
      "        unstructured_client.models.operations.get_destination.GetDestinationResponseTypedDict\n",
      "        unstructured_client.models.operations.get_job.GetJobRequestTypedDict\n",
      "        unstructured_client.models.operations.get_job.GetJobResponseTypedDict\n",
      "        unstructured_client.models.operations.get_source.GetSourceRequestTypedDict\n",
      "        unstructured_client.models.operations.get_source.GetSourceResponseTypedDict\n",
      "        unstructured_client.models.operations.get_workflow.GetWorkflowRequestTypedDict\n",
      "        unstructured_client.models.operations.get_workflow.GetWorkflowResponseTypedDict\n",
      "        unstructured_client.models.operations.list_destinations.ListDestinationsRequestTypedDict\n",
      "        unstructured_client.models.operations.list_destinations.ListDestinationsResponseTypedDict\n",
      "        unstructured_client.models.operations.list_jobs.ListJobsRequestTypedDict\n",
      "        unstructured_client.models.operations.list_jobs.ListJobsResponseTypedDict\n",
      "        unstructured_client.models.operations.list_sources.ListSourcesRequestTypedDict\n",
      "        unstructured_client.models.operations.list_sources.ListSourcesResponseTypedDict\n",
      "        unstructured_client.models.operations.list_workflows.ListWorkflowsRequestTypedDict\n",
      "        unstructured_client.models.operations.list_workflows.ListWorkflowsResponseTypedDict\n",
      "        unstructured_client.models.operations.partition.PartitionRequestTypedDict\n",
      "        unstructured_client.models.operations.partition.PartitionResponseTypedDict\n",
      "        unstructured_client.models.operations.run_workflow.RunWorkflowRequestTypedDict\n",
      "        unstructured_client.models.operations.run_workflow.RunWorkflowResponseTypedDict\n",
      "        unstructured_client.models.operations.update_destination.UpdateDestinationRequestTypedDict\n",
      "        unstructured_client.models.operations.update_destination.UpdateDestinationResponseTypedDict\n",
      "        unstructured_client.models.operations.update_source.UpdateSourceRequestTypedDict\n",
      "        unstructured_client.models.operations.update_source.UpdateSourceResponseTypedDict\n",
      "        unstructured_client.models.operations.update_workflow.UpdateWorkflowRequestTypedDict\n",
      "        unstructured_client.models.operations.update_workflow.UpdateWorkflowResponseTypedDict\n",
      "    unstructured_client.types.basemodel.BaseModel(pydantic.main.BaseModel)\n",
      "        unstructured_client.models.operations.cancel_job.CancelJobRequest\n",
      "        unstructured_client.models.operations.cancel_job.CancelJobResponse\n",
      "        unstructured_client.models.operations.create_destination.CreateDestinationRequest\n",
      "        unstructured_client.models.operations.create_destination.CreateDestinationResponse\n",
      "        unstructured_client.models.operations.create_source.CreateSourceRequest\n",
      "        unstructured_client.models.operations.create_source.CreateSourceResponse\n",
      "        unstructured_client.models.operations.create_workflow.CreateWorkflowRequest\n",
      "        unstructured_client.models.operations.create_workflow.CreateWorkflowResponse\n",
      "        unstructured_client.models.operations.delete_destination.DeleteDestinationRequest\n",
      "        unstructured_client.models.operations.delete_destination.DeleteDestinationResponse\n",
      "        unstructured_client.models.operations.delete_source.DeleteSourceRequest\n",
      "        unstructured_client.models.operations.delete_source.DeleteSourceResponse\n",
      "        unstructured_client.models.operations.delete_workflow.DeleteWorkflowRequest\n",
      "        unstructured_client.models.operations.delete_workflow.DeleteWorkflowResponse\n",
      "        unstructured_client.models.operations.get_destination.GetDestinationRequest\n",
      "        unstructured_client.models.operations.get_destination.GetDestinationResponse\n",
      "        unstructured_client.models.operations.get_job.GetJobRequest\n",
      "        unstructured_client.models.operations.get_job.GetJobResponse\n",
      "        unstructured_client.models.operations.get_source.GetSourceRequest\n",
      "        unstructured_client.models.operations.get_source.GetSourceResponse\n",
      "        unstructured_client.models.operations.get_workflow.GetWorkflowRequest\n",
      "        unstructured_client.models.operations.get_workflow.GetWorkflowResponse\n",
      "        unstructured_client.models.operations.list_destinations.ListDestinationsRequest\n",
      "        unstructured_client.models.operations.list_destinations.ListDestinationsResponse\n",
      "        unstructured_client.models.operations.list_jobs.ListJobsRequest\n",
      "        unstructured_client.models.operations.list_jobs.ListJobsResponse\n",
      "        unstructured_client.models.operations.list_sources.ListSourcesRequest\n",
      "        unstructured_client.models.operations.list_sources.ListSourcesResponse\n",
      "        unstructured_client.models.operations.list_workflows.ListWorkflowsRequest\n",
      "        unstructured_client.models.operations.list_workflows.ListWorkflowsResponse\n",
      "        unstructured_client.models.operations.partition.PartitionRequest\n",
      "        unstructured_client.models.operations.partition.PartitionResponse\n",
      "        unstructured_client.models.operations.run_workflow.RunWorkflowRequest\n",
      "        unstructured_client.models.operations.run_workflow.RunWorkflowResponse\n",
      "        unstructured_client.models.operations.update_destination.UpdateDestinationRequest\n",
      "        unstructured_client.models.operations.update_destination.UpdateDestinationResponse\n",
      "        unstructured_client.models.operations.update_source.UpdateSourceRequest\n",
      "        unstructured_client.models.operations.update_source.UpdateSourceResponse\n",
      "        unstructured_client.models.operations.update_workflow.UpdateWorkflowRequest\n",
      "        unstructured_client.models.operations.update_workflow.UpdateWorkflowResponse\n",
      "\n",
      "    class CancelJobRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  CancelJobRequest(*, job_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x1204570e0>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x1204571d0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CancelJobRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'job_id': \"Annotated[str, FieldMetadata(path=PathPa...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'job_id': FieldInfo(annotation=str, required=Tr...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"CancelJobRequest\", val...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, job_id: Annotated[str, <unstructu...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class CancelJobRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      CancelJobRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'job_id': ForwardRef('str', module='unstructured_cl...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'job_id', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'job_id', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class CancelJobResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  CancelJobResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, any: Optional[Any] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CancelJobResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'any': 'Optional[Any]', 'content_type': 'str', 'raw...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'any': FieldInfo(annotation=Union[Any, NoneType...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"CancelJobResponse\", va...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...tpx...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class CancelJobResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      CancelJobResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'any': ForwardRef('NotRequired[Any]', module='unstr...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'any', 'content_type', 'raw_response', '...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'any', 'content_type', 'raw_response', ...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class CreateDestinationRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  CreateDestinationRequest(*, create_destination_connector: Annotated[unstructured_client.models.shared.createdestinationconnector.CreateDestinationConnector, <unstructured_client.utils.metadata.FieldMetadata object at 0x120457050>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x1204573b0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CreateDestinationRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'create_destination_connector': \"Annotated[shared_c...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'create_destination_connector': FieldInfo(annot...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"CreateDestinationReque...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, create_destination_connector: Ann...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class CreateDestinationRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      CreateDestinationRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'create_destination_connector': ForwardRef('shared_...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'create_destination_connector', 'unstruc...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'create_destination_connector', 'unstru...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class CreateDestinationResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  CreateDestinationResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, destination_connector_information: Optional[unstructured_client.models.shared.destinationconnectorinformation.DestinationConnectorInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CreateDestinationResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'destination_connector_infor...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"CreateDestinationRespo...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...Des...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class CreateDestinationResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      CreateDestinationResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'destination_connector_i...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'destination_connector_...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class CreateSourceRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  CreateSourceRequest(*, create_source_connector: Annotated[unstructured_client.models.shared.createsourceconnector.CreateSourceConnector, <unstructured_client.utils.metadata.FieldMetadata object at 0x120f19700>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120f197f0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CreateSourceRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'create_source_connector': \"Annotated[shared_create...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'create_source_connector': FieldInfo(annotation...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"CreateSourceRequest\", ...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, create_source_connector: Annotate...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class CreateSourceRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      CreateSourceRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'create_source_connector': ForwardRef('shared_creat...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'create_source_connector', 'unstructured...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'create_source_connector', 'unstructure...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class CreateSourceResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  CreateSourceResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, source_connector_information: Optional[unstructured_client.models.shared.sourceconnectorinformation.SourceConnectorInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CreateSourceResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"CreateSourceResponse\",...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...tio...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class CreateSourceResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      CreateSourceResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'source_...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'source...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class CreateWorkflowRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  CreateWorkflowRequest(*, create_workflow: Annotated[unstructured_client.models.shared.createworkflow.CreateWorkflow, <unstructured_client.utils.metadata.FieldMetadata object at 0x120f1b5f0>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120f1b6e0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CreateWorkflowRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'create_workflow': \"Annotated[shared_createworkflow...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'unstructur...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'create_workflow': FieldInfo(annotation=CreateW...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"CreateWorkflowRequest\"...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, create_workflow: Annotated[unstru...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class CreateWorkflowRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      CreateWorkflowRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'create_workflow': ForwardRef('shared_createworkflo...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'create_workflow', 'unstructured_api_key...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'create_workflow', 'unstructured_api_ke...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class CreateWorkflowResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  CreateWorkflowResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, workflow_information: Optional[unstructured_client.models.shared.workflowinformation.WorkflowInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CreateWorkflowResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'unstructur...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"CreateWorkflowResponse...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...inf...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class CreateWorkflowResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      CreateWorkflowResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'status_...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'status...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class DeleteDestinationRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  DeleteDestinationRequest(*, destination_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6c440>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6c530>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      DeleteDestinationRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'destination_id': \"Annotated[str, FieldMetadata(pat...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'destination_id': FieldInfo(annotation=str, req...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"DeleteDestinationReque...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, destination_id: Annotated[str, <u...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class DeleteDestinationRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      DeleteDestinationRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'destination_id': ForwardRef('str', module='unstruc...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'destination_id', 'unstructured_api_key'...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'destination_id', 'unstructured_api_key...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class DeleteDestinationResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  DeleteDestinationResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, any: Optional[Any] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      DeleteDestinationResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'any': 'Optional[Any]', 'content_type': 'str', 'raw...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'any': FieldInfo(annotation=Union[Any, NoneType...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"DeleteDestinationRespo...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...tpx...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class DeleteDestinationResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      DeleteDestinationResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'any': ForwardRef('NotRequired[Any]', module='unstr...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'any', 'content_type', 'raw_response', '...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'any', 'content_type', 'raw_response', ...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class DeleteSourceRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  DeleteSourceRequest(*, source_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6c950>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6cad0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      DeleteSourceRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'source_id': \"Annotated[str, FieldMetadata(path=Pat...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'source_id': FieldInfo(annotation=str, required...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"DeleteSourceRequest\", ...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, source_id: Annotated[str, <unstru...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class DeleteSourceRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      DeleteSourceRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'source_id': ForwardRef('str', module='unstructured...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'source_id', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'source_id', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class DeleteSourceResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  DeleteSourceResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, any: Optional[Any] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      DeleteSourceResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'any': 'Optional[Any]', 'content_type': 'str', 'raw...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'any': FieldInfo(annotation=Union[Any, NoneType...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"DeleteSourceResponse\",...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...tpx...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class DeleteSourceResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      DeleteSourceResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'any': ForwardRef('NotRequired[Any]', module='unstr...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'any', 'content_type', 'raw_response', '...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'any', 'content_type', 'raw_response', ...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class DeleteWorkflowRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  DeleteWorkflowRequest(*, workflow_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6d3d0>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6d4c0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      DeleteWorkflowRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'unstructured_api_key': \"Annotated[OptionalNullable...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'unstructured_api_key': FieldInfo(annotation=Op...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"DeleteWorkflowRequest\"...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, workflow_id: Annotated[str, <unst...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class DeleteWorkflowRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      DeleteWorkflowRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'unstructured_api_key': ForwardRef('NotRequired[Nul...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'unstructured_api_key', 'workflow_id'})\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'unstructured_api_key', 'workflow_id'})\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class DeleteWorkflowResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  DeleteWorkflowResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, any: Optional[Any] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      DeleteWorkflowResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'any': 'Optional[Any]', 'content_type': 'str', 'raw...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'any': FieldInfo(annotation=Union[Any, NoneType...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"DeleteWorkflowResponse...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...tpx...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class DeleteWorkflowResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      DeleteWorkflowResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'any': ForwardRef('NotRequired[Any]', module='unstr...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'any', 'content_type', 'raw_response', '...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'any', 'content_type', 'raw_response', ...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class GetDestinationRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  GetDestinationRequest(*, destination_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6c830>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6d760>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GetDestinationRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'destination_id': \"Annotated[str, FieldMetadata(pat...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'destination_id': FieldInfo(annotation=str, req...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"GetDestinationRequest\"...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, destination_id: Annotated[str, <u...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class GetDestinationRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      GetDestinationRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'destination_id': ForwardRef('str', module='unstruc...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'destination_id', 'unstructured_api_key'...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'destination_id', 'unstructured_api_key...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class GetDestinationResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  GetDestinationResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, destination_connector_information: Optional[unstructured_client.models.shared.destinationconnectorinformation.DestinationConnectorInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GetDestinationResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'destination_connector_infor...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"GetDestinationResponse...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...Des...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class GetDestinationResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      GetDestinationResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'destination_connector_i...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'destination_connector_...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class GetJobRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  GetJobRequest(*, job_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6e570>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6e660>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GetJobRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'job_id': \"Annotated[str, FieldMetadata(path=PathPa...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'job_id': FieldInfo(annotation=str, required=Tr...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"GetJobRequest\", valida...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, job_id: Annotated[str, <unstructu...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class GetJobRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      GetJobRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'job_id': ForwardRef('str', module='unstructured_cl...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'job_id', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'job_id', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class GetJobResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  GetJobResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, job_information: Optional[unstructured_client.models.shared.jobinformation.JobInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GetJobResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'job_information': 'Optional...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"GetJobResponse\", valid...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...d.j...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class GetJobResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      GetJobResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'job_information', 'raw_...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'job_information', 'raw...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class GetSourceRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  GetSourceRequest(*, source_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6f140>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120f6f230>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GetSourceRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'source_id': \"Annotated[str, FieldMetadata(path=Pat...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'source_id': FieldInfo(annotation=str, required...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"GetSourceRequest\", val...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, source_id: Annotated[str, <unstru...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class GetSourceRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      GetSourceRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'source_id': ForwardRef('str', module='unstructured...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'source_id', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'source_id', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class GetSourceResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  GetSourceResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, source_connector_information: Optional[unstructured_client.models.shared.sourceconnectorinformation.SourceConnectorInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GetSourceResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"GetSourceResponse\", va...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...tio...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class GetSourceResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      GetSourceResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'source_...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'source...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class GetWorkflowRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  GetWorkflowRequest(*, workflow_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd4140>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd4230>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GetWorkflowRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'unstructured_api_key': \"Annotated[OptionalNullable...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'unstructured_api_key': FieldInfo(annotation=Op...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"GetWorkflowRequest\", v...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, workflow_id: Annotated[str, <unst...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class GetWorkflowRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      GetWorkflowRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'unstructured_api_key': ForwardRef('NotRequired[Nul...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'unstructured_api_key', 'workflow_id'})\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'unstructured_api_key', 'workflow_id'})\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class GetWorkflowResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  GetWorkflowResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, workflow_information: Optional[unstructured_client.models.shared.workflowinformation.WorkflowInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GetWorkflowResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'unstructur...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"GetWorkflowResponse\", ...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...inf...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class GetWorkflowResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      GetWorkflowResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'status_...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'status...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ListDestinationsRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  ListDestinationsRequest(*, destination_type: Annotated[OptionalNullable[unstructured_client.models.shared.destinationconnectortype.DestinationConnectorType], <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd4ce0>] = Unset(), unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd4dd0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ListDestinationsRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'destination_type': \"Annotated[OptionalNullable[sha...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'unstructur...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'destination_type': FieldInfo(annotation=Option...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"ListDestinationsReques...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, destination_type: Annotated[Optio...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class ListDestinationsRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      ListDestinationsRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'destination_type': ForwardRef('NotRequired[Nullabl...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'destination_type', 'unstructured_api_ke...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'destination_type', 'unstructured_api_k...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ListDestinationsResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  ListDestinationsResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, response_list_destinations: Optional[List[unstructured_client.models.shared.destinationconnectorinformation.DestinationConnectorInformation]] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ListDestinationsResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"ListDestinationsRespon...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...est...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class ListDestinationsResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      ListDestinationsResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'respons...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'respon...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ListJobsRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  ListJobsRequest(*, status: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd6180>] = Unset(), unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd6270>] = Unset(), workflow_id: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd6330>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ListJobsRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'status': \"Annotated[OptionalNullable[str], FieldMe...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'status': FieldInfo(annotation=OptionalNullable...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"ListJobsRequest\", vali...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, status: Annotated[OptionalNullabl...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class ListJobsRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      ListJobsRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'status': ForwardRef('NotRequired[Nullable[str]]', ...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'status', 'unstructured_api_key', 'workf...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'status', 'unstructured_api_key', 'work...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ListJobsResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  ListJobsResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, response_list_jobs: Optional[List[unstructured_client.models.shared.jobinformation.JobInformation]] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ListJobsResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"ListJobsResponse\", val...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i....jo...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class ListJobsResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      ListJobsResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'respons...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'respon...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ListSourcesRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  ListSourcesRequest(*, source_type: Annotated[OptionalNullable[unstructured_client.models.shared.sourceconnectortype.SourceConnectorType], <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd6ff0>] = Unset(), unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x120fd70e0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ListSourcesRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'source_type': \"Annotated[OptionalNullable[shared_s...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'unstructur...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'source_type': FieldInfo(annotation=OptionalNul...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"ListSourcesRequest\", v...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, source_type: Annotated[OptionalNu...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class ListSourcesRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      ListSourcesRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'source_type': ForwardRef('NotRequired[Nullable[sha...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'source_type', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'source_type', 'unstructured_api_key'})\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ListSourcesResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  ListSourcesResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, response_list_sources: Optional[List[unstructured_client.models.shared.sourceconnectorinformation.SourceConnectorInformation]] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ListSourcesResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"ListSourcesResponse\", ...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...ion...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class ListSourcesResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      ListSourcesResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'respons...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'respon...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ListWorkflowsRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  ListWorkflowsRequest(*, destination_id: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x1218341a0>] = Unset(), source_id: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x121834290>] = Unset(), status: Annotated[OptionalNullable[unstructured_client.models.shared.workflowstate.WorkflowState], <unstructured_client.utils.metadata.FieldMetadata object at 0x1218340e0>] = Unset(), unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x121834380>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ListWorkflowsRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'destination_id': \"Annotated[OptionalNullable[str],...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'destination_id': FieldInfo(annotation=Optional...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"ListWorkflowsRequest\",...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, destination_id: Annotated[Optiona...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class ListWorkflowsRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      ListWorkflowsRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'destination_id': ForwardRef('NotRequired[Nullable[...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'destination_id', 'source_id', 'status',...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'destination_id', 'source_id', 'status'...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ListWorkflowsResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  ListWorkflowsResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, response_list_workflows: Optional[List[unstructured_client.models.shared.workflowinformation.WorkflowInformation]] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ListWorkflowsResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'unstructur...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"ListWorkflowsResponse\"...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...nfo...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class ListWorkflowsResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      ListWorkflowsResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'respons...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'respon...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class PartitionRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  PartitionRequest(*, partition_parameters: Annotated[unstructured_client.models.shared.partition_parameters.PartitionParameters, <unstructured_client.utils.metadata.FieldMetadata object at 0x121835220>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x121835310>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      PartitionRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'partition_parameters': \"Annotated[shared_partition...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'partition_parameters': FieldInfo(annotation=Pa...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"PartitionRequest\", val...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, partition_parameters: Annotated[u...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class PartitionRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      PartitionRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'partition_parameters': ForwardRef('shared_partitio...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'partition_parameters', 'unstructured_ap...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'partition_parameters', 'unstructured_a...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class PartitionResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  PartitionResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, csv_elements: Optional[str] = None, elements: Optional[List[Dict[str, Any]]] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      PartitionResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'csv_elements': 'Optional[st...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"PartitionResponse\", va...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...: O...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class PartitionResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      PartitionResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'csv_elements', 'element...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'csv_elements', 'elemen...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class RunWorkflowRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  RunWorkflowRequest(*, workflow_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x121835850>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x121835940>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RunWorkflowRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'unstructured_api_key': \"Annotated[OptionalNullable...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'unstructured_client.models....\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'unstructured_api_key': FieldInfo(annotation=Op...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"RunWorkflowRequest\", v...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, workflow_id: Annotated[str, <unst...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class RunWorkflowRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      RunWorkflowRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'unstructured_api_key': ForwardRef('NotRequired[Nul...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'unstructured_api_key', 'workflow_id'})\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'unstructured_api_key', 'workflow_id'})\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class RunWorkflowResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  RunWorkflowResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, workflow_information: Optional[unstructured_client.models.shared.workflowinformation.WorkflowInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RunWorkflowResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'unstructur...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"RunWorkflowResponse\", ...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...inf...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class RunWorkflowResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      RunWorkflowResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'status_...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'status...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class UpdateDestinationRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  UpdateDestinationRequest(*, update_destination_connector: Annotated[unstructured_client.models.shared.updatedestinationconnector.UpdateDestinationConnector, <unstructured_client.utils.metadata.FieldMetadata object at 0x121834860>], destination_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x121835fd0>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x121835f40>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      UpdateDestinationRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'destination_id': \"Annotated[str, FieldMetadata(pat...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'destination_id': FieldInfo(annotation=str, req...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"UpdateDestinationReque...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, update_destination_connector: Ann...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class UpdateDestinationRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      UpdateDestinationRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'destination_id': ForwardRef('str', module='unstruc...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'destination_id', 'unstructured_api_key'...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'destination_id', 'unstructured_api_key...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class UpdateDestinationResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  UpdateDestinationResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, destination_connector_information: Optional[unstructured_client.models.shared.destinationconnectorinformation.DestinationConnectorInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      UpdateDestinationResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'destination_connector_infor...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"UpdateDestinationRespo...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...Des...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class UpdateDestinationResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      UpdateDestinationResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'destination_connector_i...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'destination_connector_...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class UpdateSourceRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  UpdateSourceRequest(*, update_source_connector: Annotated[unstructured_client.models.shared.updatesourceconnector.UpdateSourceConnector, <unstructured_client.utils.metadata.FieldMetadata object at 0x121837b60>], source_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x121837d10>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x121837dd0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      UpdateSourceRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'source_id': \"Annotated[str, FieldMetadata(path=Pat...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'source_id': FieldInfo(annotation=str, required...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"UpdateSourceRequest\", ...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, update_source_connector: Annotate...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class UpdateSourceRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      UpdateSourceRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'source_id': ForwardRef('str', module='unstructured...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'source_id', 'unstructured_api_key', 'up...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'source_id', 'unstructured_api_key', 'u...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class UpdateSourceResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  UpdateSourceResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, source_connector_information: Optional[unstructured_client.models.shared.sourceconnectorinformation.SourceConnectorInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      UpdateSourceResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"UpdateSourceResponse\",...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...tio...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class UpdateSourceResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      UpdateSourceResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'source_...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'source...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class UpdateWorkflowRequest(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  UpdateWorkflowRequest(*, update_workflow: Annotated[unstructured_client.models.shared.updateworkflow.UpdateWorkflow, <unstructured_client.utils.metadata.FieldMetadata object at 0x121895c10>], workflow_id: Annotated[str, <unstructured_client.utils.metadata.FieldMetadata object at 0x121895df0>], unstructured_api_key: Annotated[OptionalNullable[str], <unstructured_client.utils.metadata.FieldMetadata object at 0x121895eb0>] = Unset()) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      UpdateWorkflowRequest\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  serialize_model(self, handler)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'unstructured_api_key': \"Annotated[OptionalNullable...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'ref': 'unstructured_clie...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'unstructured_api_key': FieldInfo(annotation=Op...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=FunctionWrap(\n",
      "     |    ...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"UpdateWorkflowRequest\"...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, update_workflow: Annotated[unstru...ada...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class UpdateWorkflowRequestTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      UpdateWorkflowRequestTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'unstructured_api_key': ForwardRef('NotRequired[Nul...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'unstructured_api_key', 'update_workflow...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'unstructured_api_key', 'update_workflo...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class UpdateWorkflowResponse(unstructured_client.types.basemodel.BaseModel)\n",
      "     |  UpdateWorkflowResponse(*, content_type: str, status_code: int, raw_response: httpx.Response, workflow_information: Optional[unstructured_client.models.shared.workflowinformation.WorkflowInformation] = None) -> None\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      UpdateWorkflowResponse\n",
      "     |      unstructured_client.types.basemodel.BaseModel\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': 'str', 'raw_response': 'httpx.Respo...\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'unstructur...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'content_type': FieldInfo(annotation=str, requi...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"UpdateWorkflowResponse...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, content_type: str, status_code: i...inf...\n",
      "     |\n",
      "     |  model_config = {'arbitrary_types_allowed': True, 'populate_by_name': T...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from unstructured_client.types.basemodel.BaseModel:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |      Hook into generating the model's CoreSchema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source: The class we are generating a schema for.\n",
      "     |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      "     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A `pydantic-core` `CoreSchema`.\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by pydantic.\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_computed_fields\n",
      "     |      Get metadata about the computed fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields\n",
      "     |      Get metadata about the fields defined on the model.\n",
      "     |\n",
      "     |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      "     |      In V3, this property will be removed from the `BaseModel` class.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "\n",
      "    class UpdateWorkflowResponseTypedDict(builtins.dict)\n",
      "     |  Method resolution order:\n",
      "     |      UpdateWorkflowResponseTypedDict\n",
      "     |      builtins.dict\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'content_type': ForwardRef('str', module='unstructu...\n",
      "     |\n",
      "     |  __closed__ = False\n",
      "     |\n",
      "     |  __extra_items__ = None\n",
      "     |\n",
      "     |  __mutable_keys__ = frozenset({'content_type', 'raw_response', 'status_...\n",
      "     |\n",
      "     |  __optional_keys__ = frozenset()\n",
      "     |\n",
      "     |  __orig_bases__ = (<function TypedDict>,)\n",
      "     |\n",
      "     |  __readonly_keys__ = frozenset()\n",
      "     |\n",
      "     |  __required_keys__ = frozenset({'content_type', 'raw_response', 'status...\n",
      "     |\n",
      "     |  __total__ = True\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      True if the dictionary has the specified key, else False.\n",
      "     |\n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ior__(self, value, /)\n",
      "     |      Return self|=value.\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __or__(self, value, /)\n",
      "     |      Return self|value.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __reversed__(self, /)\n",
      "     |      Return a reverse iterator over the dict keys.\n",
      "     |\n",
      "     |  __ror__(self, value, /)\n",
      "     |      Return value|self.\n",
      "     |\n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |\n",
      "     |  __sizeof__(...)\n",
      "     |      D.__sizeof__() -> size of D in memory, in bytes\n",
      "     |\n",
      "     |  clear(...)\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |\n",
      "     |  copy(...)\n",
      "     |      D.copy() -> a shallow copy of D\n",
      "     |\n",
      "     |  get(self, key, default=None, /)\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  items(...)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |\n",
      "     |  keys(...)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |\n",
      "     |  pop(...)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |\n",
      "     |      If the key is not found, return the default if given; otherwise,\n",
      "     |      raise a KeyError.\n",
      "     |\n",
      "     |  popitem(self, /)\n",
      "     |      Remove and return a (key, value) pair as a 2-tuple.\n",
      "     |\n",
      "     |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      "     |      Raises KeyError if the dict is empty.\n",
      "     |\n",
      "     |  setdefault(self, key, default=None, /)\n",
      "     |      Insert key with a value of default if key is not in the dictionary.\n",
      "     |\n",
      "     |      Return the value for key if key is in the dictionary, else default.\n",
      "     |\n",
      "     |  update(...)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E is present and has a .keys() method, then does:  for k in E.keys(): D[k] = E[k]\n",
      "     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      "     |\n",
      "     |  values(...)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __class_getitem__(...)\n",
      "     |      See PEP 585\n",
      "     |\n",
      "     |  fromkeys(iterable, value=None, /)\n",
      "     |      Create a new dictionary with keys from iterable and values set to value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.dict:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) class method of builtins.dict\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from builtins.dict:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "DATA\n",
      "    CANCEL_JOB_SERVERS = {'platform-api': 'https://platform.unstructuredap...\n",
      "    CANCEL_JOB_SERVER_PLATFORM_API = 'platform-api'\n",
      "    CREATE_DESTINATION_SERVERS = {'platform-api': 'https://platform.unstru...\n",
      "    CREATE_DESTINATION_SERVER_PLATFORM_API = 'platform-api'\n",
      "    CREATE_SOURCE_SERVERS = {'platform-api': 'https://platform.unstructure...\n",
      "    CREATE_SOURCE_SERVER_PLATFORM_API = 'platform-api'\n",
      "    CREATE_WORKFLOW_SERVERS = {'platform-api': 'https://platform.unstructu...\n",
      "    CREATE_WORKFLOW_SERVER_PLATFORM_API = 'platform-api'\n",
      "    DELETE_DESTINATION_SERVERS = {'platform-api': 'https://platform.unstru...\n",
      "    DELETE_DESTINATION_SERVER_PLATFORM_API = 'platform-api'\n",
      "    DELETE_SOURCE_SERVERS = {'platform-api': 'https://platform.unstructure...\n",
      "    DELETE_SOURCE_SERVER_PLATFORM_API = 'platform-api'\n",
      "    DELETE_WORKFLOW_SERVERS = {'platform-api': 'https://platform.unstructu...\n",
      "    DELETE_WORKFLOW_SERVER_PLATFORM_API = 'platform-api'\n",
      "    GET_DESTINATION_SERVERS = {'platform-api': 'https://platform.unstructu...\n",
      "    GET_DESTINATION_SERVER_PLATFORM_API = 'platform-api'\n",
      "    GET_JOB_SERVERS = {'platform-api': 'https://platform.unstructuredapp.i...\n",
      "    GET_JOB_SERVER_PLATFORM_API = 'platform-api'\n",
      "    GET_SOURCE_SERVERS = {'platform-api': 'https://platform.unstructuredap...\n",
      "    GET_SOURCE_SERVER_PLATFORM_API = 'platform-api'\n",
      "    GET_WORKFLOW_SERVERS = {'platform-api': 'https://platform.unstructured...\n",
      "    GET_WORKFLOW_SERVER_PLATFORM_API = 'platform-api'\n",
      "    LIST_DESTINATIONS_SERVERS = {'platform-api': 'https://platform.unstruc...\n",
      "    LIST_DESTINATIONS_SERVER_PLATFORM_API = 'platform-api'\n",
      "    LIST_JOBS_SERVERS = {'platform-api': 'https://platform.unstructuredapp...\n",
      "    LIST_JOBS_SERVER_PLATFORM_API = 'platform-api'\n",
      "    LIST_SOURCES_SERVERS = {'platform-api': 'https://platform.unstructured...\n",
      "    LIST_SOURCES_SERVER_PLATFORM_API = 'platform-api'\n",
      "    LIST_WORKFLOWS_SERVERS = {'platform-api': 'https://platform.unstructur...\n",
      "    LIST_WORKFLOWS_SERVER_PLATFORM_API = 'platform-api'\n",
      "    PARTITION_SERVERS = {'development': 'http://localhost:8000', 'free-api...\n",
      "    PARTITION_SERVER_DEVELOPMENT = 'development'\n",
      "    PARTITION_SERVER_FREE_API = 'free-api'\n",
      "    PARTITION_SERVER_SAAS_API = 'saas-api'\n",
      "    RUN_WORKFLOW_SERVERS = {'platform-api': 'https://platform.unstructured...\n",
      "    RUN_WORKFLOW_SERVER_PLATFORM_API = 'platform-api'\n",
      "    UPDATE_DESTINATION_SERVERS = {'platform-api': 'https://platform.unstru...\n",
      "    UPDATE_DESTINATION_SERVER_PLATFORM_API = 'platform-api'\n",
      "    UPDATE_SOURCE_SERVERS = {'platform-api': 'https://platform.unstructure...\n",
      "    UPDATE_SOURCE_SERVER_PLATFORM_API = 'platform-api'\n",
      "    UPDATE_WORKFLOW_SERVERS = {'platform-api': 'https://platform.unstructu...\n",
      "    UPDATE_WORKFLOW_SERVER_PLATFORM_API = 'platform-api'\n",
      "    __all__ = ['CANCEL_JOB_SERVERS', 'CANCEL_JOB_SERVER_PLATFORM_API', 'CR...\n",
      "\n",
      "FILE\n",
      "    /Users/matansharon/python/AI/.venv/lib/python3.12/site-packages/unstructured_client/models/operations/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(unstructured_client.models.operations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
