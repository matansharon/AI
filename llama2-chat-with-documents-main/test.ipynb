{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from chromadb.config import Settings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import (\n",
    "    DirectoryLoader,\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    ")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "DB_CHROMA_PATH = \"./../vectorstore/db_chroma\"\n",
    "DATA_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_vector_database():\n",
    "    \"\"\"\n",
    "    Creates a vector database using document loaders and embeddings.\n",
    "\n",
    "    This function loads data from PDF, markdown and text files in the 'data/' directory,\n",
    "    splits the loaded documents into chunks, transforms them into embeddings using HuggingFace,\n",
    "    and finally persists the embeddings into a Chroma vector database.\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize loaders for different file types\n",
    "    pdf_loader = DirectoryLoader(DATA_DIR, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    markdown_loader = DirectoryLoader(\n",
    "        DATA_DIR, glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader\n",
    "    )\n",
    "    text_loader = DirectoryLoader(DATA_DIR, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "    all_loaders = [pdf_loader, markdown_loader, text_loader]\n",
    "\n",
    "    # Load documents from all loaders\n",
    "    loaded_documents = []\n",
    "    for loader in all_loaders:\n",
    "        loaded_documents.extend(loader.load())\n",
    "    # print((loaded_documents[0].metadata['source']))\n",
    "\n",
    "    # text_loader = DirectoryLoader(DATA_DIR, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "    # loaded_documents = text_loader.load()\n",
    "\n",
    "    # len(loaded_documents)\n",
    "    # loaded_documents[0]\n",
    "\n",
    "    # Split loaded documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunked_documents = text_splitter.split_documents(loaded_documents)\n",
    "    # len(chunked_documents)\n",
    "    print(chunked_documents[0].metadata[\"source\"])\n",
    "    \n",
    "    # Initialize HuggingFace embeddings\n",
    "    huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={\"device\": \"cpu\"},\n",
    "    )\n",
    "\n",
    "    # Create and persist a Chroma vector database from the chunked documents\n",
    "    # vector_database = Chroma.from_documents(\n",
    "    #     documents=chunked_documents,\n",
    "    #     embedding=huggingface_embeddings,\n",
    "    #     persist_directory=DB_CHROMA_PATH,\n",
    "    # )\n",
    "    # # vector_database.delete()\n",
    "    # # vector_database.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\2005.pdf\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    create_vector_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryLoader' object has no attribute 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\python\\opensorce_chatpdf\\test.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         loaded_documents\u001b[39m.\u001b[39mextend(loader\u001b[39m.\u001b[39mload())\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mprint\u001b[39m((loader\u001b[39m.\u001b[39mmetadata[\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m create_vector_database2()\n",
      "\u001b[1;32mf:\\python\\opensorce_chatpdf\\test.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m loader \u001b[39min\u001b[39;00m all_loaders:\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     loaded_documents\u001b[39m.\u001b[39mextend(loader\u001b[39m.\u001b[39mload())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mprint\u001b[39m((loader\u001b[39m.\u001b[39;49mmetadata[\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DirectoryLoader' object has no attribute 'metadata'"
     ]
    }
   ],
   "source": [
    "def create_vector_database2():\n",
    "    \"\"\"\n",
    "    Creates a vector database using document loaders and embeddings.\n",
    "\n",
    "    This function loads data from PDF, markdown and text files in the 'data/' directory,\n",
    "    splits the loaded documents into chunks, transforms them into embeddings using HuggingFace,\n",
    "    and finally persists the embeddings into a Chroma vector database.\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize loaders for different file types\n",
    "    pdf_loader = DirectoryLoader(DATA_DIR, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    markdown_loader = DirectoryLoader(\n",
    "        DATA_DIR, glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader\n",
    "    )\n",
    "    text_loader = DirectoryLoader(DATA_DIR, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "    all_loaders = [pdf_loader, markdown_loader, text_loader]\n",
    "\n",
    "    # Load documents from all loaders\n",
    "    loaded_documents = []\n",
    "    for loader in all_loaders:\n",
    "        loaded_documents.extend(loader.load())\n",
    "        print((loader.metadata['source']))\n",
    "create_vector_database2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x00'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mf:\\python\\opensorce_chatpdf\\test.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m path3\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path2,file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path3,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     data\u001b[39m=\u001b[39mpickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '\\x00'."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sqlite_path=r'F:\\python\\vectorstore\\db_chroma\\chroma.sqlite3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['migrations',\n",
       " 'embeddings_queue',\n",
       " 'collections',\n",
       " 'collection_metadata',\n",
       " 'segments',\n",
       " 'segment_metadata',\n",
       " 'embeddings',\n",
       " 'embedding_metadata',\n",
       " 'max_seq_id',\n",
       " 'embedding_fulltext_search',\n",
       " 'embedding_fulltext_search_data',\n",
       " 'embedding_fulltext_search_idx',\n",
       " 'embedding_fulltext_search_content',\n",
       " 'embedding_fulltext_search_docsize',\n",
       " 'embedding_fulltext_search_config']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code from chatgpt that I used to test the database\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database again\n",
    "conn = sqlite3.connect(sqlite_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve the list of tables in the database\n",
    "tables = cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "table_names = [table[0] for table in tables]\n",
    "\n",
    "table_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'key', 'string_value', 'int_value', 'float_value', 'bool_value'], dtype='object')\n",
      "{'Training Transformers with 4-bit Integers.pdf', 'QLoRA- Efficient Finetuning of Quantized LLMs.txt', 'state_of_the_union.txt', '2005.pdf'}\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "con = sqlite3.connect(sqlite_path)\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM embedding_metadata\", con)\n",
    "print(df.columns)\n",
    "dic=set()\n",
    "for i in range(len(df)):\n",
    "    row=df.iloc[i]\n",
    "    if row.key=='source':\n",
    "        dic.add(row.string_value.split('\\\\')[-1])\n",
    "print(dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(sqlite_path)\n",
    "df = pd.read_sql(\"SELECT * FROM embeddings_queue\", con)\n",
    "df.to_sql(\"embeddings_queue\", con, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2005.pdf': 25,\n",
       " 'TrainingTransformerswith4-bitIntegers.pdf': 430,\n",
       " 'QLoRA-EfficientFinetuningofQuantizedLLMs.txt': 590,\n",
       " 'state_of_the_union.txt': 215}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all the unique values in the metadata column\n",
    "\n",
    "all_files={}\n",
    "for i in range(len(df)):\n",
    "    name=(df['metadata'][i].split(',')[0].split(':')[1].replace('\"','').replace('}','').replace('{','').replace(' ','').split(',')[0].split('\\\\')[-1])\n",
    "    if name not in all_files:\n",
    "        all_files[name]=1\n",
    "    else:\n",
    "        all_files[name]+=1\n",
    "all_files\n",
    "# df['metadata'][0].split(',')[0].split(':')[1].replace('\"','').replace('}','').replace('{','').replace(' ','').split(',')[0].split('\\\\')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\python\\\\vectorstore\\\\db_chroma\\\\6230c921-d4ae-425d-b0f0-d1cf7bd55133\\\\index_metadata.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\python\\opensorce_chatpdf\\test.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#read the folowing pickle file to get the embeddings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m path\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mvectorstore\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdb_chroma\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m6230c921-d4ae-425d-b0f0-d1cf7bd55133\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mindex_metadata.pickle\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df2\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_pickle(path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python/opensorce_chatpdf/test.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df2\n",
      "File \u001b[1;32mc:\\Users\\matan.s\\AppData\\Local\\anaconda3\\envs\\open-pdf\\lib\\site-packages\\pandas\\io\\pickle.py:179\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    178\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[1;32m--> 179\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    180\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    181\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    182\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    183\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    184\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    185\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    186\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\matan.s\\AppData\\Local\\anaconda3\\envs\\open-pdf\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\python\\\\vectorstore\\\\db_chroma\\\\6230c921-d4ae-425d-b0f0-d1cf7bd55133\\\\index_metadata.pickle'"
     ]
    }
   ],
   "source": [
    "#read the folowing pickle file to get the embeddings\n",
    "path=r\"F:\\python\\vectorstore\\db_chroma\\6230c921-d4ae-425d-b0f0-d1cf7bd55133\\index_metadata.pickle\"\n",
    "\n",
    "\n",
    "df2=pd.read_pickle(path)\n",
    "df2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
