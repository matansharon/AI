{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f226a6dc15464f9580efcec32aa92a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan.s\\AppData\\Local\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\matan.s\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccf8f4d3eec436eab14d019a2d147b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36ab69854bd40238c0e9ea9c0ef7eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd7ce3ec8294ed884b393091bae586a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99a5b8571fb4ee6b94c7d053552fe25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/630 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab251a7938a4ea8a108fa9dbd6e2a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)quantize_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68d02746ba8421b8130c665f73850aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bit-128g.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "<s> ### System:\n",
      "This is a system prompt, please behave and help the user.\n",
      "\n",
      "### User:\n",
      "Tell me about AI\n",
      "\n",
      "### Assistant:\n",
      " AI, or Artificial Intelligence, is a branch of computer science that deals with the development of intelligent machines that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. AI systems are designed to learn, adapt, and improve their performance over time, making them increasingly capable of performing complex tasks. AI has a wide range of applications, including natural language processing, machine learning, and robotics. It is transforming various industries, such as healthcare, finance, and manufacturing, by automating tasks, improving efficiency, and enhancing decision-making processes.</s>\n",
      "*** Pipeline:\n",
      "### System:\n",
      "This is a system prompt, please behave and help the user.\n",
      "\n",
      "### User:\n",
      "Tell me about AI\n",
      "\n",
      "### Assistant:\n",
      " Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans do. It involves developing algorithms and systems that can process large amounts of data, recognize patterns, make decisions based on those patterns, and adapt to new situations. AI has various applications across different industries such as healthcare, finance, transportation, and entertainment. Some popular examples include chatbots, virtual assistants, self-driving cars, and machine learning models. The ultimate goal of AI researchers is to create intelligent machines that can perform tasks more efficiently than humans while maintaining their cognitive abilities.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, logging\n",
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "\n",
    "model_name_or_path = \"TheBloke/StableBeluga-7B-GPTQ\"\n",
    "model_basename = \"gptq_model-4bit-128g\"\n",
    "\n",
    "use_triton = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
    "        model_basename=model_basename,\n",
    "        use_safetensors=True,\n",
    "        trust_remote_code=False,\n",
    "        device=\"cuda:0\",\n",
    "        use_triton=use_triton,\n",
    "        quantize_config=None)\n",
    "\n",
    "\"\"\"\n",
    "To download from a specific branch, use the revision parameter, as in this example:\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
    "        revision=\"gptq-4bit-32g-actorder_True\",\n",
    "        model_basename=model_basename,\n",
    "        use_safetensors=True,\n",
    "        trust_remote_code=False,\n",
    "        device=\"cuda:0\",\n",
    "        quantize_config=None)\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''### System:\n",
    "This is a system prompt, please behave and help the user.\n",
    "\n",
    "### User:\n",
    "{prompt}\n",
    "\n",
    "### Assistant:\n",
    "'''\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "\n",
    "# Prevent printing spurious transformers error when using pipeline with AutoGPTQ\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "print(pipe(prompt_template)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a343b42751340beb619dc86feece249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8181328fc56945c0b350b2c67dfdc7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be a game changer for businesses of all sizes, but it can also be overwhelming to try and wrap your head around. Here are some key points to consider when implementing AI in your business:\n",
      "\n",
      "1. Start small: Don't try to tackle everything at once. Start with a specific pain point or process that you want to improve, and work from there.\n",
      "2. Identify your goals: Before you start implementing AI, it's important to identify what you want to achieve. Do you want to increase efficiency? Improve customer service? Reduce costs? Knowing your goals will help guide your implementation.\n",
      "3. Choose the right technology: There are many different types of AI technologies available, and not all of them will be suitable for your business. Do some research to determine which technology is best for your needs.\n",
      "4. Consider data privacy and security: AI relies on large amounts of data, and that data must be protected. Make sure you have a plan in place to keep your data safe and secure.\n",
      "5. Focus on ROI: AI can be expensive, so it's important to focus on return on investment (ROI). Make\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Llama-2-13B-chat-GGUF\", model_file=\"llama-2-13b-chat.q4_K_M.gguf\", model_type=\"llama\", gpu_layers=20)\n",
    "\n",
    "print(llm(\"AI is going to\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604566701bd843918c4b459ca2b62825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e6bc4f47cb4e56901d5b1053bfa88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " change the world in ways we can’t yet imagine\n",
      "\n",
      "Artificial intelligence (AI) has already had a profound impact on many aspects of our lives, from how we shop and work to how we communicate and access information. However, as AI technology continues to advance at an incredible pace, it is likely to have even more far-reaching consequences in the future. Here are five potential ways that AI may change the world over the next decade:\n",
      "\n",
      "1. Job displacement: One of the biggest concerns about AI is that it could displace human workers in many industries. As AI systems become more advanced, they may be able to perform tasks that were previously done by humans, leading to significant job losses. This could have a profound impact on society and could lead to increased inequality and social unrest.\n",
      "\n",
      "2. Increased automation: Related to the first point, AI is likely to increase automation in many industries. This could lead to greater efficiency and productivity, but it could also lead to job losses and a loss of human skills and expertise.\n",
      "\n",
      "3. Improved healthcare: AI has already made significant impacts in healthcare, from diagn\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Llama-2-13B-chat-GGUF\", model_file=\"llama-2-13b-chat.q4_K_M.gguf\", model_type=\"llama\", gpu_layers=30)\n",
    "\n",
    "print(llm(\"AI is going to\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' washington 09/13/16\\nGood Morning Washington : WJLA : September 13, 2016 7:00am-9:00am EDT\\nthe latest on the flooding in louisiana and the death toll continues to rise. it is important that you stay informed and keep up with the latest information from officials. we will continue to follow this story throughout the day and bring you updates as they become available. >>> now to a developing story out of north korea. the u.s. military is confirming that it has conducted a missile test off the coast of south korea. this comes amid heightened tensions between the two countries. our pentagon correspondent, barbara starr, has the latest from the pentagon. >> reporter: good morning. the u.s. military says it has successfully conducted a missile defense test in the asian sea. this is a defensive system designed to protect against north korean missiles. the test was conducted sunday and involved a ground-based interceptor launched from alaska. the pentagon says the test was successful, but the missile did not intercept the'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('good morning')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
