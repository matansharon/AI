{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 1.5418 - accuracy: 0.4378 - val_loss: 1.2591 - val_accuracy: 0.5466\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 1.1757 - accuracy: 0.5830 - val_loss: 1.0853 - val_accuracy: 0.6155\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0269 - accuracy: 0.6390 - val_loss: 0.9922 - val_accuracy: 0.6537\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9359 - accuracy: 0.6735 - val_loss: 0.9864 - val_accuracy: 0.6589\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8619 - accuracy: 0.6981 - val_loss: 0.9192 - val_accuracy: 0.6827\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8023 - accuracy: 0.7185 - val_loss: 0.9078 - val_accuracy: 0.6831\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7553 - accuracy: 0.7358 - val_loss: 0.8845 - val_accuracy: 0.6975\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7109 - accuracy: 0.7508 - val_loss: 0.9726 - val_accuracy: 0.6728\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6762 - accuracy: 0.7619 - val_loss: 0.8571 - val_accuracy: 0.7113\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6430 - accuracy: 0.7743 - val_loss: 0.9200 - val_accuracy: 0.6958\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9200 - accuracy: 0.6958\n",
      "Test accuracy: 0.6958000063896179\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create a convolutional neural network\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numba import jit, cuda\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "batch2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
    "batch3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
    "batch4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
    "batch5 = unpickle('cifar-10-batches-py/data_batch_5')\n",
    "batch_meta = unpickle('cifar-10-batches-py/batches.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.DataFrame(batch1[b'data'])\n",
    "df2 = pd.DataFrame(batch2[b'data'])\n",
    "df3 = pd.DataFrame(batch3[b'data'])\n",
    "df4 = pd.DataFrame(batch4[b'data'])\n",
    "df5 = pd.DataFrame(batch5[b'data']) \n",
    "\n",
    "#load the labels into a dataframe\n",
    "df1_labels = pd.DataFrame(batch1[b'labels'])\n",
    "df2_labels = pd.DataFrame(batch2[b'labels'])\n",
    "df3_labels = pd.DataFrame(batch3[b'labels'])\n",
    "df4_labels = pd.DataFrame(batch4[b'labels'])\n",
    "df5_labels = pd.DataFrame(batch5[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#concatenate the dataframes\n",
    "df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
    "df_labels = pd.concat([df1_labels, df2_labels, df3_labels, df4_labels, df5_labels], ignore_index=True)\n",
    "\n",
    "#load the data into a tensor\n",
    "\n",
    "data = torch.from_numpy(df.values)\n",
    "labels = torch.from_numpy(df_labels.values)\n",
    "\n",
    "#reshape the data into a 4D tensor\n",
    "data = data.reshape(50000, 3, 32, 32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan.s\\AppData\\Local\\Temp\\ipykernel_23052\\3158736793.py:7: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit(target_backend='cuda')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# print(a)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m start \u001b[39m=\u001b[39m timer()\n\u001b[1;32m---> 19\u001b[0m func(a)\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwithout GPU:\u001b[39m\u001b[39m\"\u001b[39m, timer()\u001b[39m-\u001b[39mstart)\t\n\u001b[0;32m     22\u001b[0m start \u001b[39m=\u001b[39m timer()\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mfunc\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(a):\t\t\t\t\t\t\t\t\n\u001b[0;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m----> 3\u001b[0m         a\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandn(n)\n\u001b[0;32m      4\u001b[0m         b\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(n)\n\u001b[0;32m      5\u001b[0m         c\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdot(a,b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def func(a):\t\t\t\t\t\t\t\t\n",
    "    for i in range(n):\n",
    "        a=np.random.randn(n)\n",
    "        b=np.random.randn(n)\n",
    "        c=np.dot(a,b)\n",
    "\n",
    "@jit(target_backend='cuda')\n",
    "def func2(a):\n",
    "    for i in range(n):\n",
    "        A=np.random.randn(n)\n",
    "        B=np.random.randn(n)\n",
    "        C=np.dot(A,B)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    n=100000\n",
    "    a=np.random.randn(n)\n",
    "    # print(a)\n",
    "    start = timer()\n",
    "    func(a)\n",
    "    print(\"without GPU:\", timer()-start)\t\n",
    "\t\n",
    "    start = timer()\n",
    "    func2(a)\n",
    "    print(\"with GPU:\", timer()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan.s\\AppData\\Local\\Temp\\ipykernel_23052\\4086339893.py:12: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit(target_backend='cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without GPU: 0.10602420000031998\n",
      "with GPU: 0.04593100000056438\n"
     ]
    }
   ],
   "source": [
    "from numba import jit, cuda\n",
    "import numpy as np\n",
    "# to measure exec time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# normal function to run on cpu\n",
    "def func(a):\t\t\t\t\t\t\t\t\n",
    "\tfor i in range(1000000):\n",
    "\t\ta[i]+= 1\t\n",
    "\n",
    "# function optimized to run on gpu\n",
    "@jit(target_backend='cuda')\t\t\t\t\t\t\n",
    "def func2(a):\n",
    "\tfor i in range(1000000):\n",
    "\t\ta[i]+= 1\n",
    "if __name__==\"__main__\":\n",
    "\tn = 1000000\t\t\n",
    "\ta = np.ones(n, dtype = np.float64)\n",
    "\t\n",
    "\tstart = timer()\n",
    "\tfunc(a)\n",
    "\tprint(\"without GPU:\", timer()-start)\t\n",
    "\t\n",
    "\tstart = timer()\n",
    "\tfunc2(a)\n",
    "\tprint(\"with GPU:\", timer()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 14 12:53:21 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.98                 Driver Version: 535.98       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA T1000 8GB             WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 35%   42C    P8              N/A /  50W |    917MiB /  8192MiB |      4%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      9912    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     15064    C+G   ...tionsPlus\\logioptionsplus_agent.exe    N/A      |\n",
      "|    0   N/A  N/A     15820    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     16040    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     16320    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17784    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     20140    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     20644    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     21400    C+G   ...ns\\Software\\Current\\LogiOverlay.exe    N/A      |\n",
      "|    0   N/A  N/A     25200    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     25784    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     26240    C+G   ...ft Office\\root\\Office16\\OUTLOOK.EXE    N/A      |\n",
      "|    0   N/A  N/A     27612    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     29096    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     30008    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     31364    C+G   ...26b99r8h8gj\\HPAudioControl_19H1.exe    N/A      |\n",
      "|    0   N/A  N/A     32996    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu_info= !nvidia-smi\n",
    "gpu_info='\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed')>=0:\n",
    "    print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
